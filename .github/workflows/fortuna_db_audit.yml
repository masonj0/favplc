name: "ğŸ” DB Auditor + Pipeline Health Monitor"

on:
  schedule:
    - cron: '0 4,12,20 * * *'   # 04:00, 12:00, 20:00 UTC â€” catches US morning, afternoon, evening cards
  workflow_run:
    workflows: ["List of Best Bets"]
    types:
      - completed
  workflow_dispatch:
    inputs:
      lookback_hours:
        description: 'Audit lookback window (hours)'
        required: false
        default: '72'
        type: string
      force_full_diagnostics:
        description: 'Run all diagnostic sections even if audit succeeds'
        required: false
        default: 'false'
        type: boolean

jobs:
  audit-and-diagnose:
    runs-on: ubuntu-22.04
    timeout-minutes: 25
    steps:
      - uses: actions/checkout@v6
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Restore Master Database
        uses: actions/cache/restore@v4
        with:
          path: fortuna.db
          key: fortuna-db-v3-master-
          restore-keys: fortuna-db-v3-master-

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install -r requirements.txt
          python3 -m browserforge update
          playwright install --with-deps chromium

      - name: "ğŸ”¬ Audit + Deep Diagnostics"
        env:
          PYTHONPATH: .
          LOOKBACK_HOURS: "${{ github.event.inputs.lookback_hours || '72' }}"
          FORCE_DIAG: "${{ github.event.inputs.force_full_diagnostics || 'false' }}"
        run: |
          python3 << 'PYEOF'
          import sqlite3, os, sys, asyncio, json, re, time, traceback
          from datetime import datetime, timedelta
          from pathlib import Path
          from zoneinfo import ZoneInfo
          from collections import defaultdict

          sys.path.insert(0, '.')
          import fortuna
          import fortuna_analytics

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # SETUP
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          EASTERN        = ZoneInfo("America/New_York")
          S              = os.environ.get("GITHUB_STEP_SUMMARY", "/dev/stdout")
          SNAP_DIR       = Path("_audit_snapshots")
          SNAP_DIR.mkdir(exist_ok=True)
          buf            = []
          _DEADLINE      = datetime.now() + timedelta(minutes=22)
          now_et         = datetime.now(EASTERN)
          LOOKBACK       = int(os.environ.get("LOOKBACK_HOURS", "72"))
          FORCE_DIAG     = os.environ.get("FORCE_DIAG", "false").lower() == "true"
          STANDARD_BET   = 2.00
          stale_hours    = None

          def emit(line=""):
              buf.append(line)

          def flush():
              with open(S, "a") as f:
                  f.write("\n".join(buf) + "\n")
              buf.clear()

          def deadline_exceeded():
              return datetime.now() >= _DEADLINE

          def remaining_min():
              return max(0, (_DEADLINE - datetime.now()).total_seconds() / 60)

          def save_snapshot(name, content):
              safe = re.sub(r'[^\w\-.]', '_', name)[:80]
              (SNAP_DIR / f"{safe}.txt").write_text(
                  str(content)[:100_000])

          # â”€â”€ DB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          db_path = "fortuna.db"
          db_existed = os.path.exists(db_path)
          if not db_existed:
              emit("âš ï¸ No `fortuna.db` found â€” audit will have no data.")
              sqlite3.connect(db_path).close()

          conn = sqlite3.connect(db_path)
          conn.row_factory = sqlite3.Row

          def has_table(name):
              return bool(conn.execute(
                  "SELECT 1 FROM sqlite_master "
                  "WHERE type='table' AND name=?", (name,)
              ).fetchone())

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("# ğŸ” DB Auditor + Pipeline Health Monitor\n")
          emit(f"> **Time:** {now_et.strftime('%Y-%m-%d %H:%M ET')} Â· "
               f"**Lookback:** {LOOKBACK}h Â· "
               f"**DB existed:** {'yes' if db_existed else 'NO'}\n")
          flush()

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # PHASE 1: RUN THE ACTUAL AUDIT
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("## Phase 1: Audit Execution\n")

          audit_success = False
          audit_count   = 0
          audit_error   = None

          try:
              t0 = time.time()
              # Import and run the analytics audit pipeline
              import subprocess
              result = subprocess.run(
                  ["python3", "fortuna_analytics.py",
                   "--days", "3",
                   "--lookback-hours", str(LOOKBACK),
                   "--include-lifetime-stats"],
                  capture_output=True, text=True, timeout=600,
                  env={**os.environ, "PYTHONPATH": "."}
              )
              elapsed = time.time() - t0

              emit(f"**Exit code:** {result.returncode} Â· "
                   f"**Duration:** {elapsed:.1f}s\n")

              if result.stdout:
                  # Extract key metrics from stdout
                  save_snapshot("audit_stdout", result.stdout)
                  # Show last 60 lines of output (the report)
                  lines = result.stdout.strip().split("\n")
                  emit("### Audit Report (tail)")
                  emit("```")
                  for line in lines[-60:]:
                      emit(line)
                  emit("```\n")

              if result.returncode != 0:
                  emit("### âŒ Audit stderr")
                  emit(f"```\n{result.stderr[-1500:]}\n```\n")
                  audit_error = result.stderr[-500:]
              else:
                  audit_success = True

          except subprocess.TimeoutExpired:
              emit("âŒ Audit timed out after 600s.\n")
              audit_error = "TIMEOUT"
          except Exception as e:
              emit(f"âŒ Audit failed: `{e}`\n")
              audit_error = str(e)

          flush()

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # PHASE 2: POST-AUDIT DATABASE FORENSICS
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("## Phase 2: Database Forensics\n")

          if not has_table("tips"):
              emit("âŒ `tips` table missing â€” nothing to analyze.\n")
              flush()
          else:
              # â”€â”€ 2A: Freshness â€” when did tips last arrive? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2A: Data Freshness\n")
              freshness = conn.execute("""
                  SELECT
                      MAX(start_time) as newest_tip,
                      MAX(CASE WHEN audit_completed=1
                          THEN audit_timestamp END) as newest_audit,
                      COUNT(*) as total_tips,
                      SUM(CASE WHEN audit_completed=1 THEN 1 ELSE 0 END) as audited,
                      SUM(CASE WHEN audit_completed=0 THEN 1 ELSE 0 END) as pending
                  FROM tips
              """).fetchone()

              newest = freshness['newest_tip'] or 'never'
              newest_audit = freshness['newest_audit'] or 'never'

              # Compute staleness
              stale_hours = None
              if freshness['newest_tip']:
                  try:
                      last_tip = datetime.fromisoformat(
                          str(freshness['newest_tip']).replace('Z', '+00:00'))
                      stale_hours = (now_et - last_tip.astimezone(EASTERN)
                                     ).total_seconds() / 3600
                  except Exception:
                      pass

              stale_flag = ""
              if stale_hours is not None:
                  if stale_hours > 48:
                      stale_flag = " ğŸ”´ **STALE >48h**"
                  elif stale_hours > 24:
                      stale_flag = " ğŸŸ  **>24h since last tip**"
                  elif stale_hours > 12:
                      stale_flag = " ğŸŸ¡"

              emit(f"| Metric | Value |")
              emit(f"|--------|-------|")
              emit(f"| Newest tip | `{newest}`{stale_flag} |")
              emit(f"| Newest audit | `{newest_audit}` |")
              emit(f"| Total tips | {freshness['total_tips']} |")
              emit(f"| Audited | {freshness['audited']} |")
              emit(f"| Pending | {freshness['pending']} |")
              if stale_hours is not None:
                  emit(f"| Hours since last tip | {stale_hours:.1f}h |")
              emit("")

              # â”€â”€ 2B: Discipline Ã— verdict matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2B: Discipline Ã— Verdict Matrix\n")
              emit("| Discipline | âœ… Cashed | âŒ Burned | âšª Void | â³ Pending | Hit Rate |")
              emit("|------------|-------:|-------:|------:|--------:|---------:|")

              for row in conn.execute("""
                  SELECT
                      COALESCE(discipline, '?') as disc,
                      SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                          THEN 1 ELSE 0 END) as cashed,
                      SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as burned,
                      SUM(CASE WHEN verdict='VOID' THEN 1 ELSE 0 END) as voided,
                      SUM(CASE WHEN audit_completed=0 THEN 1 ELSE 0 END) as pending,
                      COUNT(*) as total
                  FROM tips GROUP BY discipline ORDER BY total DESC
              """):
                  d = {'H':'Harness','T':'Thorough','G':'Greyhound'}.get(
                      row['disc'], row['disc'])
                  decided = row['cashed'] + row['burned']
                  hr = f"{row['cashed']/decided*100:.1f}%" if decided > 0 else "â€”"
                  emit(f"| {d} | {row['cashed']} | {row['burned']} | "
                       f"{row['voided']} | {row['pending']} | {hr} |")
              emit("")

              # â”€â”€ 2C: Hit rate vs breakeven analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2C: Hit Rate vs Breakeven Analysis\n")
              emit("The breakeven hit rate depends on actual place payouts, "
                   "NOT a fixed +$1 assumption.\n")

              be_rows = conn.execute("""
                  SELECT
                      COALESCE(discipline, '?') as disc,
                      COUNT(*) as n,
                      SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                          THEN 1 ELSE 0 END) as wins,
                      SUM(CASE WHEN verdict='BURNED'
                          THEN 1 ELSE 0 END) as losses,
                      SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                          THEN net_profit ELSE 0 END) as win_profit,
                      SUM(CASE WHEN verdict='BURNED'
                          THEN ABS(net_profit) ELSE 0 END) as loss_total,
                      SUM(net_profit) as total_pnl,
                      AVG(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                          THEN net_profit END) as avg_win,
                      AVG(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                          THEN net_profit + 2.0 END) as avg_payout
                  FROM tips
                  WHERE audit_completed=1
                    AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED')
                  GROUP BY discipline
              """).fetchall()

              if be_rows:
                  emit("| Disc | Bets | Wins | Losses | Hit% | "
                       "Avg Payout | Breakeven% | Margin | Net P&L |")
                  emit("|------|-----:|-----:|-------:|-----:|"
                       "----------:|----------:|-------:|--------:|")

                  for row in be_rows:
                      d = {'H':'Harness','T':'Thorough','G':'Greyhound'}.get(
                          row['disc'], row['disc'])
                      decided = row['wins'] + row['losses']
                      if decided == 0:
                          continue
                      hit = row['wins'] / decided * 100
                      avg_pay = row['avg_payout'] or STANDARD_BET
                      # True breakeven = loss / (loss + avg_win_payout)
                      breakeven = STANDARD_BET / avg_pay * 100 if avg_pay > 0 else 100
                      margin = hit - breakeven
                      pnl = row['total_pnl'] or 0

                      margin_icon = "ğŸŸ¢" if margin > 5 else (
                          "ğŸŸ¡" if margin > 0 else "ğŸ”´")
                      emit(f"| {d} | {decided} | {row['wins']} | "
                           f"{row['losses']} | {hit:.1f}% | "
                           f"${avg_pay:.2f} | {breakeven:.1f}% | "
                           f"{margin_icon} {margin:+.1f}pp | "
                           f"${pnl:+.2f} |")
                  emit("")
                  emit("> **Margin** = actual hit rate minus breakeven. "
                       "Green (>5pp) = profitable edge. "
                       "Red = losing money.\n")
              else:
                  emit("â„¹ï¸ No decided tips to analyze.\n")

              # â”€â”€ 2D: Rolling 7-day performance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2D: Rolling 7-Day Performance\n")
              emit("```")
              emit(f"  {'DATE':<12s} {'BETS':>4} {'W':>3} {'L':>3} "
                   f"{'HIT%':>5} {'P&L':>8} {'CUMUL':>8}")
              emit(f"  {'â”€'*12} {'â”€'*4} {'â”€'*3} {'â”€'*3} "
                   f"{'â”€'*5} {'â”€'*8} {'â”€'*8}")

              cumul = 0.0
              for row in conn.execute("""
                  SELECT
                      DATE(start_time) as d,
                      COUNT(*) as n,
                      SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                          THEN 1 ELSE 0 END) as w,
                      SUM(CASE WHEN verdict='BURNED'
                          THEN 1 ELSE 0 END) as l,
                      SUM(net_profit) as pnl
                  FROM tips
                  WHERE audit_completed=1
                    AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED')
                    AND start_time >= DATE('now', '-7 days')
                  GROUP BY d ORDER BY d
              """):
                  decided = row['w'] + row['l']
                  hr = f"{row['w']/decided*100:.0f}%" if decided else "â€”"
                  pnl = row['pnl'] or 0
                  cumul += pnl
                  bar_w = "â–ˆ" * row['w']
                  bar_l = "â–‘" * row['l']
                  emit(f"  {row['d']:<12s} {row['n']:>4} {row['w']:>3} "
                       f"{row['l']:>3} {hr:>5} ${pnl:>+7.2f} "
                       f"${cumul:>+7.2f}  {bar_w}{bar_l}")

              emit("```\n")

              # â”€â”€ 2E: Goldmine vs non-goldmine performance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2E: Goldmine vs Standard Performance\n")

              gm_col_exists = bool(conn.execute(
                  "SELECT 1 FROM pragma_table_info('tips') "
                  "WHERE name='is_goldmine'"
              ).fetchone())

              if gm_col_exists:
                  emit("| Category | Bets | Hit% | Avg Payout | Net P&L | ROI |")
                  emit("|----------|-----:|-----:|----------:|--------:|----:|")

                  for label, where in [
                      ("ğŸ† Goldmine", "is_goldmine=1"),
                      ("ğŸ“Š Standard", "is_goldmine=0 OR is_goldmine IS NULL"),
                  ]:
                      row = conn.execute(f"""
                          SELECT
                              COUNT(*) as n,
                              SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                                  THEN 1 ELSE 0 END) as w,
                              SUM(CASE WHEN verdict='BURNED'
                                  THEN 1 ELSE 0 END) as l,
                              SUM(net_profit) as pnl,
                              AVG(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                                  THEN net_profit + 2.0 END) as avg_pay
                          FROM tips
                          WHERE audit_completed=1
                            AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED')
                            AND ({where})
                      """).fetchone()
                      decided = (row['w'] or 0) + (row['l'] or 0)
                      if decided == 0:
                          emit(f"| {label} | 0 | â€” | â€” | â€” | â€” |")
                          continue
                      hr = (row['w'] or 0) / decided * 100
                      pnl = row['pnl'] or 0
                      roi = pnl / (decided * STANDARD_BET) * 100
                      avg_pay = row['avg_pay'] or STANDARD_BET
                      emit(f"| {label} | {decided} | {hr:.1f}% | "
                           f"${avg_pay:.2f} | ${pnl:+.2f} | "
                           f"{roi:+.1f}% |")
                  emit("")
              else:
                  emit("â„¹ï¸ `is_goldmine` column not found â€” "
                       "goldmine analysis skipped.\n")

              # â”€â”€ 2F: Exotic payout tracking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2F: Exotic Payout Intelligence\n")

              for exotic, label in [
                  ("superfecta_payout", "Superfecta"),
                  ("trifecta_payout", "Trifecta"),
              ]:
                  col_exists = bool(conn.execute(
                      f"SELECT 1 FROM pragma_table_info('tips') "
                      f"WHERE name='{exotic}'"
                  ).fetchone())
                  combo_exists = bool(conn.execute(
                      f"SELECT 1 FROM pragma_table_info('tips') "
                      f"WHERE name='{exotic.replace('_payout','_combination')}'"
                  ).fetchone())

                  if not col_exists:
                      continue

                  combo_col = exotic.replace('_payout','_combination') if combo_exists else "NULL"

                  erows = conn.execute(f"""
                      SELECT venue, race_number, start_time,
                             {exotic} as payout,
                             {combo_col} as combo,
                             verdict
                      FROM tips
                      WHERE {exotic} IS NOT NULL AND {exotic} > 0
                      ORDER BY {exotic} DESC LIMIT 10
                  """).fetchall()

                  if erows:
                      emit(f"**Top {label} payouts observed:**")
                      emit("```")
                      for r in erows:
                          v = r['verdict'] or '?'
                          icon = "âœ…" if v.startswith("CASH") else (
                              "âŒ" if v == "BURNED" else "âšª")
                          emit(f"  {icon} ${r['payout']:>8.2f}  "
                               f"{r['venue']:20s} R{r['race_number']}  "
                               f"{(r['start_time'] or '')[:10]}  "
                               f"{r['combo'] or ''}")
                      emit("```\n")

              # â”€â”€ 2G: Odds gap analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2G: Odds Gap vs Outcome Correlation\n")

              gap_col = bool(conn.execute(
                  "SELECT 1 FROM pragma_table_info('tips') "
                  "WHERE name='gap12'"
              ).fetchone())
              pred_odds_col = bool(conn.execute(
                  "SELECT 1 FROM pragma_table_info('tips') "
                  "WHERE name='predicted_2nd_fav_odds'"
              ).fetchone())

              if gap_col:
                  emit("| Gap Bucket | Bets | Hit% | Avg P&L | Insight |")
                  emit("|------------|-----:|-----:|--------:|---------|")

                  # Detect if gap12 is ratio or absolute based on max value
                  max_gap_raw = conn.execute(
                      "SELECT MAX(CAST(gap12 AS REAL)) FROM tips "
                      "WHERE gap12 IS NOT NULL"
                  ).fetchone()[0]
                  max_gap = float(max_gap_raw) if max_gap_raw is not None else 0.0

                  if max_gap <= 5.0:
                      # Likely ratio format (scoring memo item 1)
                      buckets = [
                          ("< 0.20 (tight)", "gap12 < 0.20"),
                          ("0.20â€“0.50", "gap12 >= 0.20 AND gap12 < 0.50"),
                          ("0.50â€“1.00", "gap12 >= 0.50 AND gap12 < 1.00"),
                          ("> 1.00 (dominant)", "gap12 >= 1.00"),
                      ]
                  else:
                      # Absolute format (pre-memo)
                      buckets = [
                          ("< 0.50 (tight)", "gap12 < 0.50"),
                          ("0.50â€“1.50", "gap12 >= 0.50 AND gap12 < 1.50"),
                          ("1.50â€“3.00", "gap12 >= 1.50 AND gap12 < 3.00"),
                          ("> 3.00 (dominant)", "gap12 >= 3.00"),
                      ]

                  for label, where in buckets:
                      row = conn.execute(f"""
                          SELECT COUNT(*) as n,
                              SUM(CASE WHEN verdict IN
                                  ('CASHED','CASHED_ESTIMATED')
                                  THEN 1 ELSE 0 END) as w,
                              SUM(CASE WHEN verdict='BURNED'
                                  THEN 1 ELSE 0 END) as l,
                              AVG(net_profit) as avg_pnl
                          FROM tips
                          WHERE audit_completed=1
                            AND verdict IN
                                ('CASHED','CASHED_ESTIMATED','BURNED')
                            AND gap12 IS NOT NULL AND {where}
                      """).fetchone()
                      decided = (row['w'] or 0) + (row['l'] or 0)
                      if decided < 2:
                          emit(f"| {label} | {decided} | â€” | â€” | "
                               f"insufficient data |")
                          continue
                      hr = (row['w'] or 0) / decided * 100
                      avg = row['avg_pnl'] or 0
                      insight = ("ğŸŸ¢ edge" if hr > 75
                                 else "ğŸŸ¡ marginal" if hr > 60
                                 else "ğŸ”´ losing")
                      emit(f"| {label} | {decided} | {hr:.1f}% | "
                           f"${avg:+.2f} | {insight} |")
                  emit("")
              else:
                  emit("â„¹ï¸ `gap12` column not found.\n")

              # â”€â”€ 2H: Predicted vs actual odds comparison â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2H: Predicted vs Actual 2nd-Fav Odds\n")

              if pred_odds_col:
                  act_col = bool(conn.execute(
                      "SELECT 1 FROM pragma_table_info('tips') "
                      "WHERE name='actual_2nd_fav_odds'"
                  ).fetchone())

                  if act_col:
                      drift_rows = conn.execute("""
                          SELECT
                              predicted_2nd_fav_odds as pred,
                              actual_2nd_fav_odds as actual,
                              venue, race_number, verdict
                          FROM tips
                          WHERE predicted_2nd_fav_odds IS NOT NULL
                            AND actual_2nd_fav_odds IS NOT NULL
                            AND audit_completed=1
                          ORDER BY start_time DESC LIMIT 20
                      """).fetchall()

                      if drift_rows:
                          emit("```")
                          emit(f"  {'VENUE':22s} R#  {'PRED':>5} â†’ "
                               f"{'ACTUAL':>6}  {'DRIFT':>6}  RESULT")
                          emit(f"  {'â”€'*22} â”€â”€  {'â”€'*5}   "
                               f"{'â”€'*6}  {'â”€'*6}  â”€â”€â”€â”€â”€â”€")
                          total_drift = 0
                          for r in drift_rows:
                              drift = (r['actual'] or 0) - (r['pred'] or 0)
                              total_drift += drift
                              icon = "âœ…" if (r['verdict'] or '').startswith(
                                  "CASH") else "âŒ"
                              emit(f"  {r['venue']:22s} "
                                   f"R{r['race_number']:<2}  "
                                   f"{r['pred']:>5.2f} â†’ "
                                   f"{r['actual']:>6.2f}  "
                                   f"{drift:>+6.2f}  {icon}")
                          avg_drift = total_drift / len(drift_rows)
                          emit(f"\n  Average drift: {avg_drift:+.2f} "
                               f"({'market softened' if avg_drift > 0 else 'market tightened'})")
                          emit("```\n")
                      else:
                          emit("â„¹ï¸ No tips with both predicted and "
                               "actual odds.\n")
                  else:
                      emit("â„¹ï¸ `actual_2nd_fav_odds` column "
                           "not found.\n")
              else:
                  emit("â„¹ï¸ `predicted_2nd_fav_odds` column not found.\n")

              # â”€â”€ 2I: Venue-level P&L leaderboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2I: Venue P&L Leaderboard\n")
              emit("```")
              emit(f"  {'VENUE':25s} {'BETS':>4} {'W':>3} {'L':>3} "
                   f"{'HIT%':>5} {'NET P&L':>8} {'ROI':>6}  TREND")
              emit(f"  {'â”€'*25} {'â”€'*4} {'â”€'*3} {'â”€'*3} "
                   f"{'â”€'*5} {'â”€'*8} {'â”€'*6}  {'â”€'*10}")

              for row in conn.execute("""
                  SELECT venue,
                      COUNT(*) as n,
                      SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                          THEN 1 ELSE 0 END) as w,
                      SUM(CASE WHEN verdict='BURNED'
                          THEN 1 ELSE 0 END) as l,
                      SUM(net_profit) as pnl
                  FROM tips
                  WHERE audit_completed=1
                    AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED')
                  GROUP BY venue
                  HAVING COUNT(*) >= 3
                  ORDER BY SUM(net_profit) DESC
              """):
                  decided = row['w'] + row['l']
                  if decided == 0:
                      continue
                  hr = row['w'] / decided * 100
                  pnl = row['pnl'] or 0
                  roi = pnl / (decided * STANDARD_BET) * 100

                  # Mini sparkline from last 5 bets at this venue
                  last5 = conn.execute("""
                      SELECT verdict FROM tips
                      WHERE venue=? AND audit_completed=1
                        AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED')
                      ORDER BY start_time DESC LIMIT 5
                  """, (row['venue'],)).fetchall()
                  spark = "".join(
                      "W" if r['verdict'].startswith("CASH") else "L"
                      for r in last5)

                  emit(f"  {row['venue']:25s} {decided:>4} "
                       f"{row['w']:>3} {row['l']:>3} "
                       f"{hr:>4.0f}% ${pnl:>+7.2f} "
                       f"{roi:>+5.1f}%  {spark}")
              emit("```\n")

              # â”€â”€ 2J: Stuck tip age distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2J: Stuck Tip Age Distribution\n")

              stuck_rows = conn.execute("""
                  SELECT
                      CASE
                          WHEN julianday('now') - julianday(start_time) < 1
                              THEN '< 24h (normal)'
                          WHEN julianday('now') - julianday(start_time) < 2
                              THEN '24â€“48h (expected)'
                          WHEN julianday('now') - julianday(start_time) < 4
                              THEN '2â€“4 days (concerning)'
                          ELSE '> 4 days (stuck)'
                      END as age_bucket,
                      COUNT(*) as n,
                      GROUP_CONCAT(DISTINCT discipline) as discs
                  FROM tips
                  WHERE audit_completed=0
                  GROUP BY age_bucket
                  ORDER BY MIN(julianday('now') - julianday(start_time))
              """).fetchall()

              if stuck_rows:
                  emit("| Age | Count | Disciplines |")
                  emit("|-----|------:|-------------|")
                  for row in stuck_rows:
                      icon = "ğŸŸ¢" if "normal" in row['age_bucket'] else (
                          "ğŸŸ¡" if "expected" in row['age_bucket'] else "ğŸ”´")
                      emit(f"| {icon} {row['age_bucket']} | "
                           f"{row['n']} | {row['discs']} |")
                  emit("")
              else:
                  emit("âœ… No stuck tips.\n")

              # â”€â”€ 2K: Scoring model columns inventory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2K: Scoring Signal Columns Inventory\n")
              emit("Checks which scoring upgrade memo columns exist "
                   "and have data.\n")

              scoring_cols = [
                  'gap12', 'market_depth', 'place_prob',
                  'predicted_ev', 'race_type', 'condition_modifier',
                  'qualification_grade', 'composite_score',
                  'is_goldmine', 'is_best_bet',
                  'predicted_2nd_fav_odds', 'actual_2nd_fav_odds',
                  'field_size', 'match_confidence',
              ]

              emit("| Column | Exists | Non-NULL | Sample |")
              emit("|--------|:------:|--------:|--------|")

              for col in scoring_cols:
                  exists = bool(conn.execute(
                      f"SELECT 1 FROM pragma_table_info('tips') "
                      f"WHERE name='{col}'"
                  ).fetchone())
                  if not exists:
                      emit(f"| `{col}` | âŒ | â€” | â€” |")
                      continue
                  stats = conn.execute(f"""
                      SELECT COUNT(*) as total,
                             SUM(CASE WHEN {col} IS NOT NULL
                                 THEN 1 ELSE 0 END) as filled
                      FROM tips
                  """).fetchone()
                  sample = conn.execute(f"""
                      SELECT {col} FROM tips
                      WHERE {col} IS NOT NULL
                      ORDER BY start_time DESC LIMIT 1
                  """).fetchone()
                  s_val = str(sample[col])[:20] if sample else "â€”"
                  pct = (stats['filled']/stats['total']*100
                         ) if stats['total'] else 0
                  emit(f"| `{col}` | âœ… | "
                       f"{stats['filled']}/{stats['total']} ({pct:.0f}%) | "
                       f"`{s_val}` |")
              emit("")

              flush()

              # â”€â”€ 2L: Qualification grade performance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              grade_col = bool(conn.execute(
                  "SELECT 1 FROM pragma_table_info('tips') "
                  "WHERE name='qualification_grade'"
              ).fetchone())

              if grade_col:
                  emit("### 2L: Performance by Qualification Grade\n")
                  emit("| Grade | Bets | Hit% | Avg P&L | "
                       "Avg Payout | Net P&L |")
                  emit("|-------|-----:|-----:|--------:|"
                       "----------:|--------:|")

                  for row in conn.execute("""
                      SELECT
                          COALESCE(qualification_grade, '?') as grade,
                          COUNT(*) as n,
                          SUM(CASE WHEN verdict IN
                              ('CASHED','CASHED_ESTIMATED')
                              THEN 1 ELSE 0 END) as w,
                          SUM(CASE WHEN verdict='BURNED'
                              THEN 1 ELSE 0 END) as l,
                          AVG(net_profit) as avg_pnl,
                          AVG(CASE WHEN verdict IN
                              ('CASHED','CASHED_ESTIMATED')
                              THEN net_profit + 2.0 END) as avg_pay,
                          SUM(net_profit) as total_pnl
                      FROM tips
                      WHERE audit_completed=1
                        AND verdict IN
                            ('CASHED','CASHED_ESTIMATED','BURNED')
                        AND qualification_grade IS NOT NULL
                      GROUP BY qualification_grade
                      ORDER BY qualification_grade
                  """):
                      decided = row['w'] + row['l']
                      if decided == 0:
                          continue
                      hr = row['w'] / decided * 100
                      emit(f"| {row['grade']} | {decided} | "
                           f"{hr:.1f}% | ${row['avg_pnl'] or 0:+.2f} | "
                           f"${row['avg_pay'] or 0:.2f} | "
                           f"${row['total_pnl'] or 0:+.2f} |")
                  emit("")
              emit("")

          flush()

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # PHASE 3: PIPELINE HEALTH CHECKS
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          run_phase3 = FORCE_DIAG or not audit_success or (
              stale_hours is not None and stale_hours > 24)

          if run_phase3:
              emit("## Phase 3: Pipeline Health Checks\n")
              emit("> _Running because: "
                   + ("forced" if FORCE_DIAG else
                      "audit failed" if not audit_success else
                      f"data stale ({stale_hours:.0f}h)")
                   + "_\n")

              # â”€â”€ 3A: Harvest log health â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 3A: Harvest Success Rate (last 7 days)\n")

              if has_table("harvest_logs"):
                  emit("| Adapter | Attempts | Success | Rate | "
                       "Avg Races | Last Success |")
                  emit("|---------|--------:|---------:|-----:|"
                       "---------:|-------------|")

                  for row in conn.execute("""
                      SELECT adapter_name,
                          COUNT(*) as attempts,
                          SUM(CASE WHEN race_count>0
                              THEN 1 ELSE 0 END) as ok,
                          AVG(race_count) as avg_rc,
                          MAX(CASE WHEN race_count>0
                              THEN timestamp END) as last_ok
                      FROM harvest_logs
                      WHERE timestamp >= DATE('now', '-7 days')
                      GROUP BY adapter_name
                      ORDER BY attempts DESC
                  """):
                      rate = (row['ok']/row['attempts']*100
                              ) if row['attempts'] else 0
                      icon = "âœ…" if rate > 60 else (
                          "ğŸŸ¡" if rate > 30 else "ğŸ”´")
                      emit(f"| {icon} `{row['adapter_name']}` | "
                           f"{row['attempts']} | {row['ok']} | "
                           f"{rate:.0f}% | {row['avg_rc'] or 0:.1f} | "
                           f"`{(row['last_ok'] or 'never')[:16]}` |")
                  emit("")
              else:
                  emit("â„¹ï¸ `harvest_logs` table not found.\n")

              # â”€â”€ 3B: Schema version â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 3B: Schema Version\n")

              if has_table("schema_version"):
                  for row in conn.execute(
                      "SELECT * FROM schema_version "
                      "ORDER BY version DESC LIMIT 1"
                  ):
                      emit(f"**Version:** {row['version']} Â· "
                           f"**Applied:** `{row['applied_at']}`\n")
                  # Check if scoring memo columns landed
                  v5_cols = ['market_depth', 'place_prob',
                             'predicted_ev', 'qualification_grade']
                  missing = [c for c in v5_cols if not bool(
                      conn.execute(
                          f"SELECT 1 FROM pragma_table_info('tips') "
                          f"WHERE name='{c}'"
                      ).fetchone())]
                  if missing:
                      emit(f"âš ï¸ Schema v5 columns missing: "
                           f"`{missing}` â€” scoring memo not deployed.\n")
                  else:
                      emit("âœ… All scoring memo v5 columns present.\n")
              else:
                  emit("â„¹ï¸ `schema_version` table not found.\n")

              # â”€â”€ 3C: Source diversity check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 3C: Source Diversity (last 7 days)\n")

              if has_table("tips"):
                  source_col = bool(conn.execute(
                      "SELECT 1 FROM pragma_table_info('tips') "
                      "WHERE name='source'"
                  ).fetchone())
                  if source_col:
                      emit("| Source | Tips | Audited | Venues |")
                      emit("|--------|-----:|--------:|--------|")
                      for row in conn.execute("""
                          SELECT COALESCE(source, '?') as src,
                              COUNT(*) as n,
                              SUM(CASE WHEN audit_completed=1
                                  THEN 1 ELSE 0 END) as ok,
                              GROUP_CONCAT(DISTINCT venue) as vs
                          FROM tips
                          WHERE start_time >= DATE('now', '-7 days')
                          GROUP BY source ORDER BY n DESC
                      """):
                          venues = (row['vs'] or '')[:60]
                          emit(f"| `{row['src']}` | {row['n']} | "
                               f"{row['ok']} | {venues} |")
                      emit("")
                  else:
                      emit("â„¹ï¸ `source` column not found.\n")

              flush()

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # PHASE 4: AUTOMATED ASSESSMENT
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("## Phase 4: ğŸ¯ Automated Assessment\n")

          findings = []
          severity = "HEALTHY"

          # Assessment 1: Audit execution
          if not audit_success:
              severity = "WARNING"
              findings.append(
                  f"ğŸŸ  **Audit failed:** `{audit_error or 'unknown'}`")

          # Assessment 2: Data freshness
          if stale_hours is not None:
              if stale_hours > 48:
                  severity = "CRITICAL"
                  findings.append(
                      f"ğŸ”´ **Pipeline stale:** no new tips in "
                      f"{stale_hours:.0f}h. Discovery pipeline may "
                      f"be broken.")
              elif stale_hours > 24:
                  if severity != "CRITICAL":
                      severity = "WARNING"
                  findings.append(
                      f"ğŸŸ  **Stale data:** {stale_hours:.0f}h since "
                      f"last tip. Check discovery workflow.")

          # Assessment 3: Stuck tips
          if has_table("tips"):
              old_stuck = conn.execute("""
                  SELECT COUNT(*) as n FROM tips
                  WHERE audit_completed=0
                    AND julianday('now') - julianday(start_time) > 4
              """).fetchone()['n']
              if old_stuck > 10:
                  if severity == "HEALTHY":
                      severity = "WARNING"
                  findings.append(
                      f"ğŸŸ  **{old_stuck} tips stuck >4 days.** "
                      f"Results adapters may not be covering "
                      f"these venues/disciplines.")

          # Assessment 4: Hit rate
          if has_table("tips"):
              overall = conn.execute("""
                  SELECT
                      SUM(CASE WHEN verdict IN
                          ('CASHED','CASHED_ESTIMATED')
                          THEN 1 ELSE 0 END) as w,
                      SUM(CASE WHEN verdict='BURNED'
                          THEN 1 ELSE 0 END) as l,
                      AVG(CASE WHEN verdict IN
                          ('CASHED','CASHED_ESTIMATED')
                          THEN net_profit + 2.0 END) as avg_pay
                  FROM tips
                  WHERE audit_completed=1
                    AND verdict IN
                        ('CASHED','CASHED_ESTIMATED','BURNED')
              """).fetchone()
              ow = overall['w'] or 0
              ol = overall['l'] or 0
              decided = ow + ol
              if decided >= 10:
                  hr = ow / decided * 100
                  avg_pay = overall['avg_pay'] or STANDARD_BET
                  be = STANDARD_BET / avg_pay * 100
                  margin = hr - be
                  if margin < -5:
                      if severity == "HEALTHY":
                          severity = "WARNING"
                      findings.append(
                          f"ğŸŸ  **Hit rate ({hr:.1f}%) is {abs(margin):.1f}pp "
                          f"below breakeven ({be:.1f}%).** "
                          f"Review qualification thresholds.")
                  elif margin > 5:
                      findings.append(
                          f"ğŸŸ¢ **Hit rate ({hr:.1f}%) is {margin:.1f}pp "
                          f"above breakeven ({be:.1f}%).** "
                          f"Edge is real and compounding.")

          # Assessment 5: DB existed
          if not db_existed:
              severity = "CRITICAL"
              findings.append(
                  "ğŸ”´ **Database not found in cache.** "
                  "All historical data may be lost. "
                  "Check cache key naming.")

          # Emit
          emit(f"### Status: **{severity}**\n")
          if not findings:
              findings.append("ğŸŸ¢ All systems nominal.")
          for f in findings:
              emit(f)
          emit("")

          # Concise action items
          emit("### Recommended Actions\n")
          if severity == "CRITICAL":
              emit("1. Check the Discovery workflow â€” is it running "
                   "and finding races?")
              emit("2. Run the Diagnostic workflow for detailed "
                   "pipeline forensics.")
              emit("3. Verify the DB cache key hasn't been "
                   "invalidated.")
          elif severity == "WARNING":
              emit("1. Check harvest logs for failing adapters.")
              emit("2. Review stuck tips â€” do they match any "
                   "result adapter's coverage?")
              emit("3. Consider running the Diagnostic workflow.")
          else:
              emit("1. No action needed. System is healthy.")
              emit("2. Monitor the 7-day rolling P&L trend.")
          emit("")

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # FOOTER
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          conn.close()
          emit(f"---\n*Audit completed at "
               f"{datetime.now(EASTERN).strftime('%Y-%m-%d %H:%M ET')} Â· "
               f"{remaining_min():.1f} min remaining.*")
          flush()
          PYEOF

      - name: Generate Legacy Summary
        if: always()
        run: |
          if [ -f scripts/generate_gha_summary.py ]; then
            python3 scripts/generate_gha_summary.py || true
          fi

      - name: Upload Audit Snapshots
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: audit-snapshots-${{ github.run_number }}
          path: _audit_snapshots/
          retention-days: 7
          if-no-files-found: ignore

      - name: Save Master Database
        if: always()
        uses: actions/cache/save@v4
        with:
          path: fortuna.db
          key: fortuna-db-v3-master-${{ github.run_number }}
