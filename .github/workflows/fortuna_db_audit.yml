name: "ğŸ” DB Auditor + Pipeline Health Monitor"

on:
  schedule:
    - cron: '0 4,12,20 * * *'   # 04:00, 12:00, 20:00 UTC â€” catches US morning, afternoon, evening cards
  workflow_run:
    workflows: ["List of Best Bets"]
    types:
      - completed
  workflow_dispatch:
    inputs:
      lookback_hours:
        description: 'Audit lookback window (hours)'
        required: false
        default: '72'
        type: string
      force_full_diagnostics:
        description: 'Run all diagnostic sections even if audit succeeds'
        required: false
        default: 'false'
        type: boolean

jobs:
  audit-and-diagnose:
    runs-on: ubuntu-22.04
    timeout-minutes: 45
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Restore Master Database
        uses: actions/cache/restore@v4
        with:
          path: fortuna.db
          key: fortuna-db-v3-master-
          restore-keys: fortuna-db-v3-master-

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install -r requirements.txt
          python3 -m browserforge update
          playwright install --with-deps chromium

      - name: "ğŸ”¬ Audit + Deep Diagnostics"
        env:
          PYTHONPATH: .
          LOOKBACK_HOURS: "${{ github.event.inputs.lookback_hours || '72' }}"
          FORCE_DIAG: "${{ github.event.inputs.force_full_diagnostics || 'false' }}"
        run: |
          python3 << 'PYEOF'
          import sqlite3, os, sys, asyncio, json, re, time, traceback
          from datetime import datetime, timedelta
          from pathlib import Path
          from zoneinfo import ZoneInfo
          from collections import defaultdict

          sys.path.insert(0, '.')
          import fortuna
          import fortuna_analytics

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # SETUP
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          EASTERN        = ZoneInfo("America/New_York")
          S              = os.environ.get("GITHUB_STEP_SUMMARY", "/dev/stdout")
          SNAP_DIR       = Path("_audit_snapshots")
          SNAP_DIR.mkdir(exist_ok=True)
          buf            = []
          _DEADLINE      = datetime.now() + timedelta(minutes=22)
          now_et         = datetime.now(EASTERN)
          LOOKBACK       = int(os.environ.get("LOOKBACK_HOURS", "72"))
          FORCE_DIAG     = os.environ.get("FORCE_DIAG", "false").lower() == "true"
          STANDARD_BET   = 2.00
          stale_hours    = None

          def emit(line=""):
              buf.append(line)

          def flush():
              with open(S, "a") as f:
                  f.write("\n".join(buf) + "\n")
              buf.clear()

          def deadline_exceeded():
              return datetime.now() >= _DEADLINE

          def remaining_min():
              return max(0, (_DEADLINE - datetime.now()).total_seconds() / 60)

          def save_snapshot(name, content):
              safe = re.sub(r'[^\w\-.]', '_', name)[:80]
              (SNAP_DIR / f"{safe}.txt").write_text(
                  str(content)[:100_000])

          # â”€â”€ DB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          db_path = "fortuna.db"
          db_existed = os.path.exists(db_path)
          if not db_existed:
              emit("âš ï¸ No `fortuna.db` found â€” audit will have no data.")
              sqlite3.connect(db_path).close()

          conn = sqlite3.connect(db_path)
          conn.row_factory = sqlite3.Row

          def has_table(name):
              return bool(conn.execute(
                  "SELECT 1 FROM sqlite_master "
                  "WHERE type='table' AND name=?", (name,)
              ).fetchone())

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("# ğŸ” DB Auditor + Pipeline Health Monitor\n")
          emit(f"> **Time:** {now_et.strftime('%Y-%m-%d %H:%M ET')} Â· "
               f"**Lookback:** {LOOKBACK}h Â· "
               f"**DB existed:** {'yes' if db_existed else 'NO'}\n")
          flush()

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # PHASE 1: RUN THE ACTUAL AUDIT
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("## Phase 1: Audit Execution\n")

          audit_success = False
          audit_count   = 0
          audit_error   = None

          try:
              t0 = time.time()
              # Import and run the analytics audit pipeline
              import subprocess
              result = subprocess.run(
                  ["python3", "fortuna_analytics.py",
                   "--days", "3",
                   "--lookback-hours", str(LOOKBACK),
                   "--include-lifetime-stats"],
                  capture_output=True, text=True, timeout=600,
                  env={**os.environ, "PYTHONPATH": "."}
              )
              elapsed = time.time() - t0

              emit(f"**Exit code:** {result.returncode} Â· "
                   f"**Duration:** {elapsed:.1f}s\n")

              if result.stdout:
                  # Extract key metrics from stdout
                  save_snapshot("audit_stdout", result.stdout)
                  # Show last 60 lines of output (the report)
                  lines = result.stdout.strip().split("\n")
                  emit("### Audit Report (tail)")
                  emit("```")
                  for line in lines[-60:]:
                      emit(line)
                  emit("```\n")

              if result.returncode != 0:
                  emit("### âŒ Audit stderr")
                  emit(f"```\n{result.stderr[-1500:]}\n```\n")
                  audit_error = result.stderr[-500:]
              else:
                  audit_success = True

          except subprocess.TimeoutExpired:
              emit("âŒ Audit timed out after 600s.\n")
              audit_error = "TIMEOUT"
          except Exception as e:
              emit(f"âŒ Audit failed: `{e}`\n")
              audit_error = str(e)

          flush()

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # PHASE 2: POST-AUDIT DATABASE FORENSICS
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("## Phase 2: Database Forensics\n")

          if not has_table("tips"):
              emit("âŒ `tips` table missing â€” nothing to analyze.\n")
              flush()
          else:
              # â”€â”€ 2A: Freshness â€” when did tips last arrive? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2A: Data Freshness\n")
              freshness = conn.execute("""
                  SELECT
                      MAX(start_time) as newest_tip,
                      MAX(CASE WHEN audit_completed=1
                          THEN audit_timestamp END) as newest_audit,
                      COUNT(*) as total_tips,
                      SUM(CASE WHEN audit_completed=1 THEN 1 ELSE 0 END) as audited,
                      SUM(CASE WHEN audit_completed=0 THEN 1 ELSE 0 END) as pending
                  FROM tips
              """).fetchone()

              newest = freshness['newest_tip'] or 'never'
              newest_audit = freshness['newest_audit'] or 'never'

              # Compute staleness based on report_date (tip insertion time) instead of future start_time (Item 10)
              stale_hours = None
              try:
                  last_report = conn.execute("SELECT MAX(report_date) FROM tips").fetchone()[0]
                  if last_report:
                      # report_date is ISO format Eastern time
                      last_tip_time = datetime.fromisoformat(last_report.replace('Z', '+00:00'))
                      # Ensure both are offset-aware for comparison
                      if last_tip_time.tzinfo is None:
                          last_tip_time = last_tip_time.replace(tzinfo=EASTERN)

                      stale_hours = (now_et - last_tip_time).total_seconds() / 3600
              except Exception as e:
                  emit(f"<!-- Staleness calc error: {e} -->")

              stale_flag = ""
              if stale_hours is not None:
                  if stale_hours > 48:
                      stale_flag = " ğŸ”´ **STALE >48h**"
                  elif stale_hours > 24:
                      stale_flag = " ğŸŸ  **>24h since last tip**"
                  elif stale_hours > 12:
                      stale_flag = " ğŸŸ¡"

              emit(f"| Metric | Value |")
              emit(f"|--------|-------|")
              emit(f"| Newest tip | `{newest}`{stale_flag} |")
              emit(f"| Newest audit | `{newest_audit}` |")
              emit(f"| Total tips | {freshness['total_tips']} |")
              emit(f"| Audited | {freshness['audited']} |")
              emit(f"| Pending | {freshness['pending']} |")
              if stale_hours is not None:
                  emit(f"| Hours since last tip | {stale_hours:.1f}h |")
              emit("")

              # â”€â”€ 2B: Discipline Ã— verdict matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2B: Discipline Ã— Verdict Matrix\n")
              emit("| Discipline | âœ… Cashed | âŒ Burned | âšª Void | â³ Pending | Hit Rate |")
              emit("|------------|-------:|-------:|------:|--------:|---------:|")

              for row in conn.execute("""
                  SELECT
                      COALESCE(discipline, '?') as disc,
                      SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                          THEN 1 ELSE 0 END) as cashed,
                      SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as burned,
                      SUM(CASE WHEN verdict='VOID' THEN 1 ELSE 0 END) as voided,
                      SUM(CASE WHEN audit_completed=0 THEN 1 ELSE 0 END) as pending,
                      COUNT(*) as total
                  FROM tips GROUP BY discipline ORDER BY total DESC
              """):
                  d = {'H':'Harness','T':'Thorough','G':'Greyhound'}.get(
                      row['disc'], row['disc'])
                  decided = row['cashed'] + row['burned']
                  hr = f"{row['cashed']/decided*100:.1f}%" if decided > 0 else "â€”"
                  emit(f"| {d} | {row['cashed']} | {row['burned']} | "
                       f"{row['voided']} | {row['pending']} | {hr} |")
              emit("")

              # â”€â”€ 2C: Hit rate vs breakeven analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2C: Hit Rate vs Breakeven Analysis\n")
              emit("The breakeven hit rate depends on actual place payouts, "
                   "NOT a fixed +$1 assumption.\n")

              be_rows = conn.execute("""
                  SELECT
                      COALESCE(discipline, '?') as disc,
                      COUNT(*) as n,
                      SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                          THEN 1 ELSE 0 END) as wins,
                      SUM(CASE WHEN verdict='BURNED'
                          THEN 1 ELSE 0 END) as losses,
                      SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                          THEN net_profit ELSE 0 END) as win_profit,
                      SUM(CASE WHEN verdict='BURNED'
                          THEN ABS(net_profit) ELSE 0 END) as loss_total,
                      SUM(net_profit) as total_pnl,
                      AVG(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                          THEN net_profit END) as avg_win,
                      AVG(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED')
                          THEN net_profit + 2.0 END) as avg_payout
                  FROM tips
                  WHERE audit_completed=1
                    AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED')
                  GROUP BY discipline
              """).fetchall()

              if be_rows:
                  emit("| Disc | Bets | Wins | Losses | Hit% | "
                       "Avg Payout | Breakeven% | Margin | Net P&L |")
                  emit("|------|-----:|-----:|-------:|-----:|"
                       "----------:|----------:|-------:|--------:|")

                  for row in be_rows:
                      d = {'H':'Harness','T':'Thorough','G':'Greyhound'}.get(
                          row['disc'], row['disc'])
                      decided = row['wins'] + row['losses']
                      if decided == 0:
                          continue
                      hit = row['wins'] / decided * 100
                      avg_pay = row['avg_payout'] or STANDARD_BET
                      # True breakeven = loss / (loss + avg_win_payout)
                      breakeven = STANDARD_BET / avg_pay * 100 if avg_pay > 0 else 100
                      margin = hit - breakeven
                      pnl = row['total_pnl'] or 0

                      margin_icon = "ğŸŸ¢" if margin > 5 else (
                          "ğŸŸ¡" if margin > 0 else "ğŸ”´")
                      emit(f"| {d} | {decided} | {row['wins']} | "
                           f"{row['losses']} | {hit:.1f}% | "
                           f"${avg_pay:.2f} | {breakeven:.1f}% | "
                           f"{margin_icon} {margin:+.1f}pp | "
                           f"${pnl:+.2f} |")
                  emit("")
                  emit("> **Margin** = actual hit rate minus breakeven. "
                       "Green (>5pp) = profitable edge. "
                       "Red = losing money.\n")
              else:
                  emit("â„¹ï¸ No decided tips to analyze.\n")

              # â”€â”€ 2D: Rolling 7-Day Performance (Sparkline Rewrite) â”€â”€â”€â”€â”€â”€
              emit("### 2D: Rolling 7-Day Performance\n")
              emit("```")
              emit(f"  {'DATE':<12s} {'BETS':>4} {'W':>3} {'L':>3} {'HIT%':>5} {'P&L':>8} {'CUMUL':>8}  FORM")
              emit(f"  {'â”€'*12} {'â”€'*4} {'â”€'*3} {'â”€'*3} {'â”€'*5} {'â”€'*8} {'â”€'*8}  {'â”€'*10}")

              cumul = 0.0
              for row in conn.execute("""
                  SELECT DATE(start_time) as d,
                         COUNT(*) as n,
                         SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w,
                         SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l,
                         SUM(net_profit) as pnl,
                         GROUP_CONCAT(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 'W' ELSE 'L' END) as sequence
                  FROM (SELECT start_time, verdict, net_profit FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') ORDER BY start_time ASC)
                  WHERE start_time >= DATE('now', '-7 days')
                  GROUP BY d ORDER BY d
              """):
                  decided = row['w'] + row['l']
                  hr = f"{row['w']/decided*100:.0f}%" if decided else "â€”"
                  pnl = row['pnl'] or 0
                  cumul += pnl
                  seq = (row['sequence'] or "").split(',')[-10:] # last 10 of day
                  spark = "".join("â–ˆ" if v == 'W' else "â–‘" for v in seq)
                  emit(f"  {row['d']:<12s} {row['n']:>4} {row['w']:>3} {row['l']:>3} {hr:>5} ${pnl:>+7.2f} ${cumul:>+7.2f}  {spark}")
              emit("```\n")

              # â”€â”€ 2E: Goldmine vs Best Bet vs Standard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2E: Tiered Performance (Goldmine/Best/Standard)\n")
              emit("```")
              emit(f"  {'CATEGORY':<15s} {'BETS':>4} {'HIT%':>6} {'AVG PAY':>8} {'NET P&L':>9} {'ROI':>7}")
              emit(f"  {'â”€'*15} {'â”€'*4} {'â”€'*6} {'â”€'*8} {'â”€'*9} {'â”€'*7}")

              gm_exists = bool(conn.execute("SELECT 1 FROM pragma_table_info('tips') WHERE name='is_goldmine'").fetchone())
              bb_exists = bool(conn.execute("SELECT 1 FROM pragma_table_info('tips') WHERE name='is_best_bet'").fetchone())

              tiers = [
                  ("ğŸ† Goldmine", "is_goldmine=1" if gm_exists else "0=1"),
                  ("â­ Best Bet", "is_best_bet=1" if bb_exists else "0=1"),
                  ("ğŸ“Š Standard", f"({ 'is_goldmine=0' if gm_exists else '1=1' }) AND ({ 'is_best_bet=0' if bb_exists else '1=1' })")
              ]

              for label, where in tiers:
                  row = conn.execute(f"""
                      SELECT COUNT(*) as n,
                             SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w,
                             SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l,
                             SUM(net_profit) as pnl,
                             AVG(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN net_profit + 2.0 END) as avg_pay
                      FROM tips
                      WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') AND ({where})
                  """).fetchone()
                  decided = (row['w'] or 0) + (row['l'] or 0)
                  if decided == 0:
                      emit(f"  {label:<15s} {0:>4} {'â€”':>6} {'â€”':>8} {'â€”':>9} {'â€”':>7}")
                      continue
                  hr = (row['w'] or 0) / decided * 100
                  pnl = row['pnl'] or 0
                  roi = pnl / (decided * STANDARD_BET) * 100
                  avg_pay = row['avg_pay'] or STANDARD_BET
                  emit(f"  {label:<15s} {decided:>4} {hr:>5.1f}% ${avg_pay:>7.2f} ${pnl:>+8.2f} {roi:>+6.1f}%")
              emit("```\n")

              # â”€â”€ 2F: Superfecta Keybox Performance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2F: Superfecta Keybox Performance\n")
              sk_exists = bool(conn.execute("SELECT 1 FROM pragma_table_info('tips') WHERE name='is_superfecta_key'").fetchone())
              if sk_exists:
                  row = conn.execute("""
                      SELECT COUNT(*) as n,
                             SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w,
                             SUM(CASE WHEN superfecta_payout > 0 THEN 1 ELSE 0 END) as super_hits,
                             SUM(CASE WHEN trifecta_payout > 0 THEN 1 ELSE 0 END) as tri_hits,
                             AVG(superfecta_payout) FILTER (WHERE superfecta_payout > 0) as avg_super
                      FROM tips
                      WHERE is_superfecta_key = 1 AND audit_completed = 1
                  """).fetchone()

                  if row and row['n'] > 0:
                      emit("```")
                      emit(f"  Attempts: {row['n']}")
                      emit(f"  Place Hit Rate: {(row['w']/row['n']*100):.1f}%")
                      emit(f"  Superfecta Hits: {row['super_hits']} ({(row['super_hits']/row['n']*100):.1f}%)")
                      emit(f"  Trifecta Hits:   {row['tri_hits']} ({(row['tri_hits']/row['n']*100):.1f}%)")
                      if row['avg_super']:
                          emit(f"  Avg Super Payout: ${row['avg_super']:.2f}")
                      emit("```\n")
                  else:
                      emit("â„¹ï¸ No audited Superfecta Keybox attempts found.\n")
              else:
                  emit("â„¹ï¸ `is_superfecta_key` column not found.\n")

              # â”€â”€ 2G: Exotic Payout Intelligence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2G: Exotic Payout Intelligence (Top 5)\n")
              emit("```")
              for exotic, label in [("superfecta_payout", "SUPER"), ("trifecta_payout", "TRI")]:
                  col_exists = bool(conn.execute(f"SELECT 1 FROM pragma_table_info('tips') WHERE name='{exotic}'").fetchone())
                  if not col_exists: continue

                  rows = conn.execute(f"SELECT venue, race_number, {exotic} as p, verdict FROM tips WHERE {exotic} > 0 ORDER BY {exotic} DESC LIMIT 5").fetchall()
                  for r in rows:
                      icon = "âœ…" if (r['verdict'] or '').startswith("CASH") else "âŒ"
                      emit(f"  {label:5s} ${r['p']:>8.2f} {icon} {(r['venue'] or '?')[:18]:18s} R{r['race_number']}")
              emit("```\n")

              # â”€â”€ 2H: Odds Gap Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2H: Odds Gap vs Outcome Correlation\n")

              gap_col = bool(conn.execute(
                  "SELECT 1 FROM pragma_table_info('tips') "
                  "WHERE name='gap12'"
              ).fetchone())
              pred_odds_col = bool(conn.execute(
                  "SELECT 1 FROM pragma_table_info('tips') "
                  "WHERE name='predicted_2nd_fav_odds'"
              ).fetchone())

              if gap_col:
                  emit("```")
                  emit(f"  {'GAP BUCKET':<20s} {'BETS':>4} {'HIT%':>6} {'AVG P&L':>8} INSIGHT")
                  emit(f"  {'â”€'*20} {'â”€'*4} {'â”€'*6} {'â”€'*8} {'â”€'*10}")

                  max_gap_raw = conn.execute("SELECT MAX(CAST(gap12 AS REAL)) FROM tips WHERE gap12 IS NOT NULL").fetchone()[0]
                  max_gap = float(max_gap_raw) if max_gap_raw is not None else 0.0

                  if max_gap <= 5.0:
                      buckets = [("< 0.20 (tight)", "gap12 < 0.20"), ("0.20â€“0.50", "gap12 >= 0.20 AND gap12 < 0.50"), ("0.50â€“1.00", "gap12 >= 0.50 AND gap12 < 1.00"), ("> 1.00 (dominant)", "gap12 >= 1.00")]
                  else:
                      buckets = [("< 0.50 (tight)", "gap12 < 0.50"), ("0.50â€“1.50", "gap12 >= 0.50 AND gap12 < 1.50"), ("1.50â€“3.00", "gap12 >= 1.50 AND gap12 < 3.00"), ("> 3.00 (dominant)", "gap12 >= 3.00")]

                  for label, where in buckets:
                      row = conn.execute(f"SELECT COUNT(*) as n, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, AVG(net_profit) as avg_pnl FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') AND gap12 IS NOT NULL AND {where}").fetchone()
                      decided = row['n']
                      if decided < 2: continue
                      hr = row['w'] / decided * 100
                      avg = row['avg_pnl'] or 0
                      insight = "ğŸŸ¢ edge" if hr > 75 else "ğŸŸ¡ marginal" if hr > 60 else "ğŸ”´ losing"
                      emit(f"  {label:<20s} {decided:>4} {hr:>5.1f}% ${avg:>7.2f}  {insight}")
                  emit("```\n")
              else:
                  emit("â„¹ï¸ `gap12` column not found.\n")

              # â”€â”€ 2I: Odds Drift Logic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2I: Odds Drift Logic (Predicted vs Actual)\n")
              if pred_odds_col:
                  act_col = bool(conn.execute("SELECT 1 FROM pragma_table_info('tips') WHERE name='actual_2nd_fav_odds'").fetchone())
                  if act_col:
                      drift_rows = conn.execute("""
                          SELECT predicted_2nd_fav_odds as pred, actual_2nd_fav_odds as actual, venue, race_number, verdict
                          FROM tips WHERE pred IS NOT NULL AND actual IS NOT NULL AND audit_completed=1
                          ORDER BY start_time DESC LIMIT 15
                      """).fetchall()
                      if drift_rows:
                          emit("```")
                          emit(f"  {'VENUE':22s} R#  {'PRED':>5} â†’ {'ACTUAL':>6}  {'DRIFT':>6}  RESULT")
                          emit(f"  {'â”€'*22} â”€â”€  {'â”€'*5}   {'â”€'*6}  {'â”€'*6}  â”€â”€â”€â”€â”€â”€")
                          for r in drift_rows:
                              drift = (r['actual'] or 0) - (r['pred'] or 0)
                              icon = "âœ…" if (r['verdict'] or '').startswith("CASH") else "âŒ"
                              emit(f"  {(r['venue'] or '?')[:22]:22s} R{r['race_number']:<2}  {r['pred']:>5.2f} â†’ {r['actual']:>6.2f}  {drift:>+6.2f}  {icon}")
                          emit("```\n")

              # â”€â”€ 2J: Venue Leaderboard (Trend Sparkline Fix) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2J: Venue P&L Leaderboard (Min 3 Bets)\n")
              emit("```")
              emit(f"  {'VENUE':25s} {'BETS':>4} {'W':>3} {'L':>3} {'HIT%':>5} {'NET P&L':>8}  TREND")
              emit(f"  {'â”€'*25} {'â”€'*4} {'â”€'*3} {'â”€'*3} {'â”€'*5} {'â”€'*8}  {'â”€'*10}")

              for row in conn.execute("""
                  SELECT venue, COUNT(*) as n,
                         SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w,
                         SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l,
                         SUM(net_profit) as pnl
                  FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED')
                  GROUP BY venue HAVING n >= 3 ORDER BY pnl DESC
              """):
                  hr = row['w'] / (row['w']+row['l']) * 100
                  last5 = conn.execute("SELECT verdict FROM tips WHERE venue=? AND audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') ORDER BY start_time DESC LIMIT 5", (row['venue'],)).fetchall()
                  spark = "".join("â–ˆ" if r['verdict'].startswith("CASH") else "â–‘" for r in reversed(last5))
                  emit(f"  {(row['venue'] or '?')[:25]:25s} {row['n']:>4} {row['w']:>3} {row['l']:>3} {hr:>4.0f}% ${row['pnl']:>+7.2f}  {spark}")
              emit("```\n")

              # â”€â”€ 2K: Stuck Tip Age Distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2K: Stuck Tip Age Distribution\n")

              stuck_rows = conn.execute("""
                  SELECT
                      CASE
                          WHEN julianday('now') - julianday(start_time) < 1
                              THEN '< 24h (normal)'
                          WHEN julianday('now') - julianday(start_time) < 2
                              THEN '24â€“48h (expected)'
                          WHEN julianday('now') - julianday(start_time) < 4
                              THEN '2â€“4 days (concerning)'
                          ELSE '> 4 days (stuck)'
                      END as age_bucket,
                      COUNT(*) as n,
                      GROUP_CONCAT(DISTINCT discipline) as discs
                  FROM tips
                  WHERE audit_completed=0
                  GROUP BY age_bucket
                  ORDER BY MIN(julianday('now') - julianday(start_time))
              """).fetchall()

              if stuck_rows:
                  emit("| Age | Count | Disciplines |")
                  emit("|-----|------:|-------------|")
                  for row in stuck_rows:
                      icon = "ğŸŸ¢" if "normal" in row['age_bucket'] else (
                          "ğŸŸ¡" if "expected" in row['age_bucket'] else "ğŸ”´")
                      emit(f"| {icon} {row['age_bucket']} | "
                           f"{row['n']} | {row['discs']} |")
                  emit("")
              else:
                  emit("âœ… No stuck tips.\n")

              # â”€â”€ 2L: Scoring Signal Columns Inventory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2L: Scoring Signal Columns Inventory\n")
              emit("Checks which scoring upgrade memo columns exist "
                   "and have data.\n")

              scoring_cols = [
                  'gap12', 'market_depth', 'place_prob',
                  'predicted_ev', 'race_type', 'condition_modifier',
                  'qualification_grade', 'composite_score',
                  'is_goldmine', 'is_best_bet',
                  'predicted_2nd_fav_odds', 'actual_2nd_fav_odds',
                  'field_size', 'match_confidence',
              ]

              emit("| Column | Exists | Non-NULL | Sample |")
              emit("|--------|:------:|--------:|--------|")

              for col in scoring_cols:
                  exists = bool(conn.execute(
                      f"SELECT 1 FROM pragma_table_info('tips') "
                      f"WHERE name='{col}'"
                  ).fetchone())
                  if not exists:
                      emit(f"| `{col}` | âŒ | â€” | â€” |")
                      continue
                  stats = conn.execute(f"""
                      SELECT COUNT(*) as total,
                             SUM(CASE WHEN {col} IS NOT NULL
                                 THEN 1 ELSE 0 END) as filled
                      FROM tips
                  """).fetchone()
                  sample = conn.execute(f"""
                      SELECT {col} FROM tips
                      WHERE {col} IS NOT NULL
                      ORDER BY start_time DESC LIMIT 1
                  """).fetchone()
                  s_val = str(sample[col])[:20] if sample else "â€”"
                  pct = (stats['filled']/stats['total']*100
                         ) if stats['total'] else 0
                  emit(f"| `{col}` | âœ… | "
                       f"{stats['filled']}/{stats['total']} ({pct:.0f}%) | "
                       f"`{s_val}` |")
              emit("")

              flush()

              # â”€â”€ 2M: Performance by Qualification Grade â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              grade_col = bool(conn.execute("SELECT 1 FROM pragma_table_info('tips') WHERE name='qualification_grade'").fetchone())

              if grade_col:
                  emit("### 2M: Performance by Qualification Grade\n")
                  emit("```")
                  emit(f"  {'GRADE':<6} {'BETS':>4} {'HIT%':>6} {'AVG P&L':>8} {'AVG PAY':>8} {'NET P&L':>9}")
                  emit(f"  {'â”€'*6} {'â”€'*4} {'â”€'*6} {'â”€'*8} {'â”€'*8} {'â”€'*9}")

                  for row in conn.execute("""
                      SELECT COALESCE(qualification_grade, '?') as grade,
                             COUNT(*) as n,
                             SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w,
                             SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l,
                             AVG(net_profit) as avg_pnl,
                             AVG(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN net_profit + 2.0 END) as avg_pay,
                             SUM(net_profit) as total_pnl
                      FROM tips
                      WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') AND qualification_grade IS NOT NULL
                      GROUP BY qualification_grade ORDER BY qualification_grade
                  """):
                      decided = row['w'] + row['l']
                      if decided == 0: continue
                      hr = row['w'] / decided * 100
                      emit(f"  {row['grade']:<6} {decided:>4} {hr:>5.1f}% ${row['avg_pnl'] or 0:>7.2f} ${row['avg_pay'] or 0:>7.2f} ${row['total_pnl'] or 0:>8.2f}")
                  emit("```\n")

              # â”€â”€ 2N: Loss Streaks (Current & Worst) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2N: Loss Streaks (Current & Worst)\n")
              streak_rows = conn.execute("SELECT verdict FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') ORDER BY start_time DESC LIMIT 100").fetchall()
              if streak_rows:
                  current_streak, worst_streak, temp_streak, first = 0, 0, 0, True
                  for r in streak_rows:
                      if not (r['verdict'] or '').startswith("CASH"): temp_streak += 1
                      else:
                          if first: current_streak = temp_streak
                          worst_streak = max(worst_streak, temp_streak); temp_streak = 0; first = False
                  worst_streak = max(worst_streak, temp_streak)
                  if first: current_streak = temp_streak
                  emit("```")
                  emit(f"  Current Loss Streak: {current_streak}")
                  emit(f"  Worst Loss Streak (Last 100): {worst_streak}")
                  emit("```\n")

              # â”€â”€ 2O: Field Size Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2O: Performance by Field Size\n")
              emit("```")
              emit(f"  {'FIELD SIZE':<12} {'BETS':>4} {'HIT%':>6} {'NET P&L':>8}")
              emit(f"  {'â”€'*12} {'â”€'*4} {'â”€'*6} {'â”€'*8}")
              for row in conn.execute("""
                  SELECT CASE WHEN field_size <= 6 THEN 'Small (2-6)' WHEN field_size <= 9 THEN 'Mid (7-9)' ELSE 'Large (10+)' END as cat,
                         COUNT(*) as n, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(net_profit) as pnl
                  FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') AND field_size IS NOT NULL
                  GROUP BY cat ORDER BY MIN(field_size)
              """):
                  hr = row['w'] / row['n'] * 100
                  emit(f"  {row['cat']:<12} {row['n']:>4} {hr:>5.1f}% ${row['pnl']:>+7.2f}")
              emit("```\n")

              # â”€â”€ 2P: Adapter Coverage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2P: Discovery Adapter Coverage (Last 7 Days)\n")
              emit("```")
              emit(f"  {'ADAPTER':<30} {'TIPS':>5} {'VENUES':>6}")
              emit(f"  {'â”€'*30} {'â”€'*5} {'â”€'*6}")
              for row in conn.execute("""
                  SELECT source, COUNT(*) as n, COUNT(DISTINCT venue) as vs
                  FROM tips WHERE start_time >= DATE('now', '-7 days')
                  GROUP BY source ORDER BY n DESC
              """):
                  emit(f"  {(row['source'] or '?')[:30]:<30} {row['n']:>5} {row['vs']:>6}")
              emit("```\n")

              # â”€â”€ 2Q: Pipeline Health â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2Q: Scoring Pipeline Health\n")
              if has_table("harvest_logs"):
                  row = conn.execute("SELECT COUNT(*) as attempts, SUM(CASE WHEN race_count > 0 THEN 1 ELSE 0 END) as success FROM harvest_logs WHERE timestamp >= DATE('now', '-24 hours')").fetchone()
                  rate = (row['success']/row['attempts']*100) if row['attempts'] else 0
                  emit(f"- Harvest Success (24h): {row['success']}/{row['attempts']} ({rate:.1f}%)")
              tips_24h = conn.execute("SELECT COUNT(*) FROM tips WHERE report_date >= DATE('now', '-24 hours')").fetchone()[0]
              emit(f"- Discovery Throughput (24h): {tips_24h} tips")
              emit("")

              # â”€â”€ 2S: Time of Day Distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2S: Tip Distribution by Time of Day (ET)\n")
              emit("```")
              for row in conn.execute("""
                  SELECT strftime('%H', datetime(start_time, '-5 hours')) as hr, COUNT(*) as n
                  FROM tips WHERE start_time >= DATE('now', '-7 days')
                  GROUP BY hr ORDER BY hr
              """):
                  bar = "â–ˆ" * (row['n'] // max(1, (tips_24h // 20)))
                  emit(f"  {row['hr']}:00  {bar} ({row['n']})")
              emit("```\n")

              # â”€â”€ 2T: Data Quality Assertions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2T: Data Quality Assertions\n")
              assertions = []
              # Check 1: Null Score
              null_scores = conn.execute("SELECT COUNT(*) FROM tips WHERE composite_score IS NULL AND start_time >= DATE('now', '-2 days')").fetchone()[0]
              if null_scores > 5: assertions.append(f"âŒ {null_scores} recent tips missing composite_score")
              else: assertions.append("âœ… Scoring variance healthy")
              # Check 2: Venue Normalization
              unknowns = conn.execute("SELECT COUNT(*) FROM tips WHERE venue = 'unknown'").fetchone()[0]
              if unknowns > 0: assertions.append(f"âŒ {unknowns} tips with 'unknown' venue")
              else: assertions.append("âœ… Venue normalization stable")
              # Check 3: Field Size population
              no_field = conn.execute("SELECT COUNT(*) FROM tips WHERE field_size IS NULL AND audit_completed=1").fetchone()[0]
              if no_field > 0: assertions.append(f"âš ï¸ {no_field} audited tips missing field_size")
              for a in assertions: emit(f"- {a}")
              emit("")

          flush()

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # PHASE 3: PIPELINE HEALTH CHECKS
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          run_phase3 = FORCE_DIAG or not audit_success or (
              stale_hours is not None and stale_hours > 24)

          if run_phase3:
              emit("## Phase 3: Pipeline Health Checks\n")
              emit("> _Running because: "
                   + ("forced" if FORCE_DIAG else
                      "audit failed" if not audit_success else
                      f"data stale ({stale_hours:.0f}h)")
                   + "_\n")

              # â”€â”€ 3A: Harvest log health â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 3A: Harvest Success Rate (last 7 days)\n")

              if has_table("harvest_logs"):
                  emit("| Adapter | Attempts | Success | Rate | "
                       "Avg Races | Last Success |")
                  emit("|---------|--------:|---------:|-----:|"
                       "---------:|-------------|")

                  for row in conn.execute("""
                      SELECT adapter_name,
                          COUNT(*) as attempts,
                          SUM(CASE WHEN race_count>0
                              THEN 1 ELSE 0 END) as ok,
                          AVG(race_count) as avg_rc,
                          MAX(CASE WHEN race_count>0
                              THEN timestamp END) as last_ok
                      FROM harvest_logs
                      WHERE timestamp >= DATE('now', '-7 days')
                      GROUP BY adapter_name
                      ORDER BY attempts DESC
                  """):
                      rate = (row['ok']/row['attempts']*100
                              ) if row['attempts'] else 0
                      icon = "âœ…" if rate > 60 else (
                          "ğŸŸ¡" if rate > 30 else "ğŸ”´")
                      emit(f"| {icon} `{row['adapter_name']}` | "
                           f"{row['attempts']} | {row['ok']} | "
                           f"{rate:.0f}% | {row['avg_rc'] or 0:.1f} | "
                           f"`{(row['last_ok'] or 'never')[:16]}` |")
                  emit("")
              else:
                  emit("â„¹ï¸ `harvest_logs` table not found.\n")

              # â”€â”€ 3B: Schema version â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 3B: Schema Version\n")

              if has_table("schema_version"):
                  for row in conn.execute(
                      "SELECT * FROM schema_version "
                      "ORDER BY version DESC LIMIT 1"
                  ):
                      emit(f"**Version:** {row['version']} Â· "
                           f"**Applied:** `{row['applied_at']}`\n")
                  # Check if scoring memo columns landed
                  v5_cols = ['market_depth', 'place_prob',
                             'predicted_ev', 'qualification_grade']
                  missing = [c for c in v5_cols if not bool(
                      conn.execute(
                          f"SELECT 1 FROM pragma_table_info('tips') "
                          f"WHERE name='{c}'"
                      ).fetchone())]
                  if missing:
                      emit(f"âš ï¸ Schema v5 columns missing: "
                           f"`{missing}` â€” scoring memo not deployed.\n")
                  else:
                      emit("âœ… All scoring memo v5 columns present.\n")
              else:
                  emit("â„¹ï¸ `schema_version` table not found.\n")

              # â”€â”€ 3C: Source diversity check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 3C: Source Diversity (last 7 days)\n")

              if has_table("tips"):
                  source_col = bool(conn.execute(
                      "SELECT 1 FROM pragma_table_info('tips') "
                      "WHERE name='source'"
                  ).fetchone())
                  if source_col:
                      emit("| Source | Tips | Audited | Venues |")
                      emit("|--------|-----:|--------:|--------|")
                      for row in conn.execute("""
                          SELECT COALESCE(source, '?') as src,
                              COUNT(*) as n,
                              SUM(CASE WHEN audit_completed=1
                                  THEN 1 ELSE 0 END) as ok,
                              GROUP_CONCAT(DISTINCT venue) as vs
                          FROM tips
                          WHERE start_time >= DATE('now', '-7 days')
                          GROUP BY source ORDER BY n DESC
                      """):
                          venues = (row['vs'] or '')[:60]
                          emit(f"| `{row['src']}` | {row['n']} | "
                               f"{row['ok']} | {venues} |")
                      emit("")
                  else:
                      emit("â„¹ï¸ `source` column not found.\n")

              flush()

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # PHASE 4: AUTOMATED ASSESSMENT (ENHANCED)
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("## Phase 4: ğŸ¯ Automated Assessment\n")
          findings, severity = [], "HEALTHY"

          if not audit_success: severity, findings = "WARNING", [f"ğŸŸ  **Audit failed:** `{audit_error or 'unknown'}`"]
          if stale_hours and stale_hours > 48: severity, findings = "CRITICAL", findings + [f"ğŸ”´ **Pipeline stale:** {stale_hours:.0f}h"]
          elif stale_hours and stale_hours > 24: severity = "WARNING"; findings.append(f"ğŸŸ  **Stale data:** {stale_hours:.0f}h")

          if has_table("tips"):
              old_stuck = conn.execute("SELECT COUNT(*) FROM tips WHERE audit_completed=0 AND julianday('now')-julianday(start_time)>4").fetchone()[0]
              if old_stuck > 10: severity = "WARNING"; findings.append(f"ğŸŸ  **{old_stuck} tips stuck >4 days**")

              res = conn.execute("SELECT SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, COUNT(*) as n, AVG(net_profit+2.0) as pay FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED')").fetchone()
              if res and res['n'] >= 10:
                  hr, be = res['w']/res['n']*100, (2.0/res['pay']*100 if res['pay'] else 100)
                  if hr - be < -5: severity = "WARNING"; findings.append(f"ğŸŸ  **Hit rate ({hr:.1f}%) < Breakeven ({be:.1f}%)**")
                  elif hr - be > 5: findings.append(f"ğŸŸ¢ **Edge confirmed: {hr-be:+.1f}pp over breakeven**")

          if not db_existed: severity, findings = "CRITICAL", findings + ["ğŸ”´ **Database not found in cache**"]

          emit(f"### Status: **{severity}**\n")
          for f in findings or ["ğŸŸ¢ All systems nominal."]: emit(f)
          emit("\n### Recommended Actions")
          if severity == "CRITICAL": emit("1. Check Discovery workflow\n2. Run Diagnostic workflow\n3. Verify cache keys")
          elif severity == "WARNING": emit("1. Check harvest logs\n2. Review stuck tips\n3. Monitor 7-day trend")
          else: emit("1. No action needed\n2. Monitor daily throughput")
          emit("")

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # FOOTER
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          conn.close()
          emit(f"---\n*Audit completed at "
               f"{datetime.now(EASTERN).strftime('%Y-%m-%d %H:%M ET')} Â· "
               f"{remaining_min():.1f} min remaining.*")
          flush()
          PYEOF

      - name: Generate Legacy Summary
        if: always()
        run: |
          if [ -f scripts/generate_gha_summary.py ]; then
            python3 scripts/generate_gha_summary.py || true
          fi

      - name: Upload Audit Snapshots
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: audit-snapshots-${{ github.run_number }}
          path: _audit_snapshots/
          retention-days: 7
          if-no-files-found: ignore

      - name: Save Master Database
        if: always()
        uses: actions/cache/save@v4
        with:
          path: fortuna.db
          key: fortuna-db-v3-master-${{ github.run_number }}
