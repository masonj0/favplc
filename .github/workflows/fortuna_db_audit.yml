name: "ğŸ” DB Auditor + Pipeline Health Monitor"

on:
  schedule:
    - cron: '0 4,12,20 * * *'
  workflow_run:
    workflows: ["List of Best Bets"]
    types:
      - completed
  workflow_dispatch:
    inputs:
      lookback_hours:
        description: 'Audit lookback window (hours)'
        required: false
        default: '72'
        type: string
      force_full_diagnostics:
        description: 'Run all diagnostic sections even if audit succeeds'
        required: false
        default: 'false'
        type: boolean

jobs:
  audit-and-diagnose:
    runs-on: ubuntu-22.04
    timeout-minutes: 45
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'    # Must match codebase target (was 3.11)

      - name: Restore Master Database
        uses: actions/cache/restore@v4
        with:
          path: fortuna.db
          key: fortuna-db-v3-master-
          restore-keys: fortuna-db-v3-master-

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install -r requirements.txt
          python3 -m browserforge update
          playwright install --with-deps chromium

      - name: "ğŸ”¬ Audit + Deep Diagnostics"
        env:
          PYTHONPATH: .
          LOOKBACK_HOURS: "${{ github.event.inputs.lookback_hours || '72' }}"
          FORCE_DIAG: "${{ github.event.inputs.force_full_diagnostics || 'false' }}"
        run: |
          python3 << 'PYEOF'
          import sqlite3, os, sys, asyncio, json, re, time, traceback, subprocess
          from datetime import datetime, timedelta
          from pathlib import Path
          from zoneinfo import ZoneInfo
          from collections import defaultdict

          sys.path.insert(0, '.')
          import fortuna
          import fortuna_analytics

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # SETUP & CONSTANTS
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          EASTERN        = ZoneInfo("America/New_York")
          S              = os.environ.get("GITHUB_STEP_SUMMARY", "/dev/stdout")
          SNAP_DIR       = Path("_audit_snapshots")
          SNAP_DIR.mkdir(exist_ok=True)
          buf            = []
          # BUG-1 Fix: Increased deadline to 35m to accommodate longer audit execution
          _DEADLINE      = datetime.now() + timedelta(minutes=35)
          now_et         = datetime.now(EASTERN)
          LOOKBACK       = int(os.environ.get("LOOKBACK_HOURS", "72"))
          FORCE_DIAG     = os.environ.get("FORCE_DIAG", "false").lower() == "true"
          STANDARD_BET   = 2.00
          STALE_HOURS    = 999.0

          def emit(line=""): buf.append(line)
          def flush():
              with open(S, "a") as f: f.write("\n".join(buf) + "\n")
              buf.clear()
          def remaining_min(): return max(0, (_DEADLINE - datetime.now()).total_seconds() / 60)
          def save_snapshot(name, content):
              safe = re.sub(r'[^\w\-.]', '_', name)[:80]
              (SNAP_DIR / f"{safe}.txt").write_text(str(content)[:100_000])

          # â”€â”€ DB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          db_path = "fortuna.db"
          db_existed = os.path.exists(db_path)
          if not db_existed:
              sqlite3.connect(db_path).close()

          conn = sqlite3.connect(db_path)
          conn.row_factory = sqlite3.Row

          def has_table(name):
              return bool(conn.execute("SELECT 1 FROM sqlite_master WHERE type='table' AND name=?", (name,)).fetchone())
          def has_col(col):
              return bool(conn.execute(f"SELECT 1 FROM pragma_table_info('tips') WHERE name='{col}'").fetchone())

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("# ğŸ” DB Auditor + Pipeline Health Monitor v3.1\n")
          emit(f"> **Time:** {now_et.strftime('%Y-%m-%d %H:%M ET')} Â· **Lookback:** {LOOKBACK}h Â· **Status:** {'Active' if db_existed else 'RECONSTRUCTING'}\n")
          flush()

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # PHASE 1: RUN THE ACTUAL AUDIT
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("## Phase 1: Audit Execution\n")
          audit_success = False
          audit_error   = None

          try:
              t0 = time.time()
              # BUG-1 Fix: Increased timeout to 1200s to handle large batches and browser overhead
              result = subprocess.run(
                  ["python3", "fortuna_analytics.py", "--days", "3", "--lookback-hours", str(LOOKBACK), "--include-lifetime-stats"],
                  capture_output=True, text=True, timeout=1200, env={**os.environ, "PYTHONPATH": "."}
              )
              elapsed = time.time() - t0
              emit(f"**Exit code:** {result.returncode} Â· **Duration:** {elapsed:.1f}s\n")
              if result.stdout:
                  save_snapshot("audit_stdout", result.stdout)
                  lines = result.stdout.strip().split("\n")
                  emit("### Audit Report (tail)\n```text")
                  for line in lines[-60:]: emit(line)
                  emit("```\n")
              if result.stderr:
                  save_snapshot("audit_stderr", result.stderr)
              if result.returncode != 0:
                  emit("### âŒ Audit stderr\n```text\n" + result.stderr[-1500:] + "\n```\n")
                  audit_error = result.stderr[-500:]
              else:
                  audit_success = True
          except subprocess.TimeoutExpired as e:
              # Capture whatever partial output was produced before the timeout
              partial_out = e.stdout or ''
              partial_err = e.stderr or ''
              if partial_out:
                  save_snapshot("audit_stdout_partial", partial_out)
              if partial_err:
                  save_snapshot("audit_stderr_partial", partial_err)
              emit(f"âŒ Audit execution timed out after {e.timeout}s\n")
              if partial_err:
                  emit(f"### Partial stderr\n```text\n{partial_err[-1000:]}\n```\n")
              elif partial_out:
                  lines = partial_out.strip().split("\n")
                  emit(f"### Partial stdout (last 30 lines)\n```text")
                  for line in lines[-30:]: emit(line)
                  emit("```\n")
              audit_error = f'Timed out after {e.timeout}s'
          except Exception as e:
              emit(f"âŒ Audit execution failed: `{e}`\n")
              audit_error = str(e)
          flush()

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # PRE-SCAN: Gather data needed for assessment
          # (computed here so assessment can appear before forensic details)
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          dq = []
          total, audited, pending = 0, 0, 0
          if has_table("tips"):
              f = conn.execute("SELECT MAX(start_time), MAX(audit_timestamp), COUNT(*), SUM(CASE WHEN audit_completed=1 THEN 1 ELSE 0 END), SUM(CASE WHEN audit_completed=0 THEN 1 ELSE 0 END), MAX(report_date) FROM tips").fetchone()
              total, audited, pending = f[2], f[3] or 0, f[4] or 0
              try:
                  if f[5]:
                      last_tip_et = datetime.fromisoformat(f[5]).replace(tzinfo=EASTERN)
                      STALE_HOURS = (now_et - last_tip_et).total_seconds() / 3600
                  else: STALE_HOURS = 999.0
              except: STALE_HOURS = 999.0

              # Pre-compute data quality assertions
              sc = conn.execute("SELECT start_time, venue, selection_number, COUNT(*) as ct FROM tips GROUP BY start_time, venue, selection_number HAVING ct > 1").fetchall()
              if sc: dq.append(f"âŒ SELECTION CLONES: {len(sc)} duplicate plays.")
              if has_col('is_goldmine'):
                  gm = conn.execute("SELECT COUNT(*) FROM tips WHERE is_goldmine=1").fetchone()[0]
                  if total and gm > total * 0.5: dq.append(f"âŒ INFLATION: {gm}/{total} Goldmines (>50%).")
              if has_col('gap12') and has_col('is_goldmine'):
                  bg = conn.execute("SELECT COUNT(*) FROM tips WHERE is_goldmine=1 AND CAST(gap12 AS REAL) < 0.2").fetchone()[0]
                  if bg: dq.append(f"âŒ LOGIC: {bg} Goldmines have gap < 0.2.")
              ns = conn.execute("SELECT COUNT(*) FROM tips WHERE gap12 IS NULL AND market_depth IS NULL").fetchone()[0]
              if total and ns > total * 0.2: dq.append(f"âŒ NULL SCORING: {ns}/{total} tips missing signals.")
              ud = conn.execute("SELECT COUNT(*) FROM tips WHERE discipline IS NULL OR discipline='?'").fetchone()[0]
              if ud: dq.append(f"âŒ DISCIPLINE: {ud} tips missing discipline.")
              fa = conn.execute("SELECT COUNT(*) FROM tips WHERE audit_completed=1 AND julianday(audit_timestamp) < julianday(start_time)").fetchone()[0]
              if fa: dq.append(f"âŒ TIME TRAVEL: {fa} tips audited before they ran.")
              zo = conn.execute("SELECT COUNT(*) FROM tips WHERE predicted_2nd_fav_odds = 0").fetchone()[0]
              if zo: dq.append(f"âŒ ZERO ODDS: {zo} tips have 0.0 odds.")
              uv = conn.execute("SELECT COUNT(*) FROM tips WHERE venue IS NULL OR venue='Unknown' OR venue='unknown'").fetchone()[0]
              if total and uv > total * 0.1: dq.append(f"âŒ UNKNOWN: {uv} unmatchable venues.")

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # ACTION PLAN (emitted FIRST â€” before forensic details)
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("## ğŸ¯ Action Plan\n")
          findings = []
          severity = "HEALTHY"

          if not audit_success:
              severity = "WARNING"
              findings.append(f"ğŸŸ  **Audit partial or failed:** `{audit_error or 'Unknown exit code'}`")

          if STALE_HOURS > 48:
              severity = "CRITICAL"
              findings.append(f"ğŸ”´ **Pipeline STALE ({STALE_HOURS:.1f}h):** Discovery might be blocked.")
          elif STALE_HOURS > 24:
              if severity != "CRITICAL": severity = "WARNING"
              findings.append(f"ğŸŸ  **Data Lagging ({STALE_HOURS:.1f}h):** Check individual adapter health.")

          # Hit rate margin assessment
          if has_table("tips"):
              overall = conn.execute("SELECT SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l, AVG(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN net_profit + 2.0 END) as ap FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED')").fetchone()
              ow, ol, ap = (overall['w'] or 0), (overall['l'] or 0), (overall['ap'] or 2.0)
              dec = ow + ol
              if dec >= 10:
                  hr, be = ow/dec*100, 2.0/ap*100
                  margin = hr - be
                  if margin < -5:
                      if severity == "HEALTHY": severity = "WARNING"
                      findings.append(f"ğŸŸ  **Performance Alert:** Hit rate ({hr:.1f}%) is {abs(margin):.1f}pp below breakeven.")
                  elif margin > 5:
                      findings.append(f"ğŸŸ¢ **Performance Edge:** Hit rate ({hr:.1f}%) is {margin:.1f}pp above breakeven.")

              # Loss streak assessment
              res = conn.execute("SELECT verdict FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') ORDER BY start_time DESC LIMIT 10").fetchall()
              if res:
                  streak = 0
                  for x in res:
                      if x['verdict'] == 'BURNED': streak += 1
                      else: break
                  if streak >= 5:
                      if severity != "CRITICAL": severity = "WARNING"
                      findings.append(f"ğŸŸ  **Alert:** Current loss streak is {streak}. Review qualification thresholds.")

          # Scoring columns health check
          if has_table("tips") and total and total > 0:
              for critical_col in ['qualification_grade', 'composite_score', 'market_depth']:
                  if has_col(critical_col):
                      filled = conn.execute(f"SELECT COUNT(*) FROM tips WHERE {critical_col} IS NOT NULL AND {critical_col} != '' AND {critical_col} != 0").fetchone()[0]
                      if filled == 0:
                          if severity == "HEALTHY": severity = "WARNING"
                          findings.append(f"ğŸŸ¡ **Scoring Gap:** `{critical_col}` is 0% populated â€” check log_tips.")

          # Section 2T escalation
          dq_errors = [f for f in (dq if 'dq' in locals() else []) if "âŒ" in f]
          if dq_errors:
              severity = "CRITICAL"
              findings.append(f"ğŸ”´ **Data Integrity Failure:** {len(dq_errors)} critical assertions failed (Section 2T).")

          emit(f"### Status: **{severity}**\n")
          if not findings: findings.append("ğŸŸ¢ All systems nominal.")
          for f in findings: emit(f)
          emit("\n### Recommended Actions\n")
          if severity == "CRITICAL":
              emit("1. RE-DEPLOY discovery adapters.")
              emit("2. PURGE corrupted data (Section 2T).")
              emit("3. Check proxy health.")
              emit("4. If scoring columns NULL: verify BUG-10 fix (log_tips) is deployed.")
          elif severity == "WARNING":
              emit("1. Check Phase 3 harvest logs for failures.")
              emit("2. Review stuck tips age distribution.")
              emit("3. If audit timed out: verify BUG-1 fix (Persistent Browser Sessions) is deployed.")
          else: emit("1. System healthy. Monitor ROI trend.")
          emit("\n---\n*Audit assessment completed at " + datetime.now(EASTERN).strftime('%Y-%m-%d %H:%M ET') + "*")
          flush()

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # PHASE 2: DATABASE FORENSICS
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("## Phase 2: Database Forensics\n")
          if not has_table("tips"):
              emit("âŒ `tips` table missing â€” forensic analysis impossible.\n")
          else:
              # â”€â”€ 2A: Freshness â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2A: Data Freshness\n```text")
              f = conn.execute("SELECT MAX(start_time), MAX(audit_timestamp), COUNT(*), SUM(CASE WHEN audit_completed=1 THEN 1 ELSE 0 END), SUM(CASE WHEN audit_completed=0 THEN 1 ELSE 0 END), MAX(report_date) FROM tips").fetchone()
              emit(f"  {'Metric':<25} {'Value':<30}")
              emit(f"  {'â”€'*25} {'â”€'*30}")
              emit(f"  {'Newest Tip (Start)':<25} {f[0] or 'Never'}")
              emit(f"  {'Newest Audit':<25} {f[1] or 'Never'}")
              emit(f"  {'Total Tips':<25} {total}")
              emit(f"  {'Audited / Pending':<25} {audited} / {pending}")
              emit(f"  {'Hours Since Last Tip':<25} {STALE_HOURS:.1f}h")
              emit("```\n")
              flush()

              # â”€â”€ 2B: Discipline Matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2B: Discipline Matrix\n```text")
              emit(f"  {'DISCIPLINE':<15} {'CASHED':>8} {'BURNED':>8} {'VOID':>8} {'PENDING':>8} {'HIT RATE':>10}")
              emit(f"  {'â”€'*15} {'â”€'*8} {'â”€'*8} {'â”€'*8} {'â”€'*8} {'â”€'*10}")
              for r in conn.execute("SELECT COALESCE(discipline,'?') as d, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l, SUM(CASE WHEN verdict='VOID' THEN 1 ELSE 0 END) as v, SUM(CASE WHEN audit_completed=0 THEN 1 ELSE 0 END) as p FROM tips GROUP BY d ORDER BY w+l DESC"):
                  dec = r['w'] + r['l']
                  hr = f"{r['w']/dec*100:6.1f}%" if dec > 0 else "      â€”"
                  name = {'H':'Harness','T':'Thoroughbred','G':'Greyhound'}.get(r['d'], r['d'])
                  emit(f"  {name:<15} {r['w']:>8} {r['l']:>8} {r['v']:>8} {r['p']:>8} {hr}")
              emit("```\n")

              # â”€â”€ 2C: Breakeven Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2C: Hit Rate vs Breakeven\n```text")
              emit(f"  {'DISC':<14} {'BETS':>5} {'HIT%':>7} {'AVG PAY':>8} {'BE%':>7} {'MARGIN':>8} {'NET P&L':>10}")
              emit(f"  {'â”€'*14} {'â”€'*5} {'â”€'*7} {'â”€'*8} {'â”€'*7} {'â”€'*8} {'â”€'*10}")
              for r in conn.execute("SELECT COALESCE(discipline,'?') as d, COUNT(*) as n, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l, AVG(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN net_profit + 2.0 END) as ap, SUM(net_profit) as pnl FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') GROUP BY discipline"):
                  dec = r['w'] + r['l']
                  if dec == 0: continue
                  hr = r['w'] / dec * 100
                  ap = r['ap'] or 2.0
                  be = 2.0 / ap * 100 if ap > 0 else 100
                  mg = hr - be
                  icon = "++" if mg > 5 else ("--" if mg < 0 else "  ")
                  name = {'H':'Harness','T':'Thoroughbred','G':'Greyhound'}.get(r['d'], r['d'] or '?')
                  emit(f"  {name:<14} {dec:>5} {hr:>6.1f}% ${ap:>6.2f} {be:>6.1f}% {icon}{mg:>+5.1f}p ${(r['pnl'] or 0):>+8.2f}")
              emit("```\n")
              flush()

              # â”€â”€ 2D: Rolling 7-Day Performance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2D: Rolling 7-Day Performance\n```text")
              emit(f"  {'DATE':<12} {'BETS':>4} {'W':>3} {'L':>3} {'HIT%':>5} {'P&L':>8} {'CUMUL':>8}  PROGRESS")
              emit(f"  {'â”€'*12} {'â”€'*4} {'â”€'*3} {'â”€'*3} {'â”€'*5} {'â”€'*8} {'â”€'*8}  {'â”€'*20}")
              cum = 0.0
              for r in conn.execute("SELECT DATE(start_time) as d, COUNT(*) as n, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l, SUM(net_profit) as pnl FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') AND start_time >= DATE('now','-7 days') GROUP BY d ORDER BY d"):
                  dec = r['w'] + r['l']
                  hr = f"{r['w']/dec*100:3.0f}%" if dec else " â€” "
                  cum += (r['pnl'] or 0)
                  bw, bl = min(r['w'], 20), min(r['l'], 20)
                  bar = "â–ˆ" * bw + "â–‘" * bl
                  emit(f"  {(r['d'] or 'unknown'):<12} {r['n']:>4} {r['w']:>3} {r['l']:>3} {hr:>5} ${(r['pnl'] or 0):>+7.2f} ${cum:>+7.2f}  {bar}")
              emit("```\n")

              # â”€â”€ 2E: Goldmine vs Standard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2E: Goldmine vs Standard Performance\n```text")
              if has_col('is_goldmine'):
                  emit(f"  {'CATEGORY':<12} {'BETS':>5} {'HIT%':>7} {'AVG PAY':>8} {'NET P&L':>10} {'ROI':>8}")
                  emit(f"  {'â”€'*12} {'â”€'*5} {'â”€'*7} {'â”€'*8} {'â”€'*10} {'â”€'*8}")
                  for label, cond in [("ğŸ† Goldmine", "is_goldmine=1"), ("ğŸ“Š Standard", "is_goldmine=0 OR is_goldmine IS NULL")]:
                      r = conn.execute(f"SELECT COUNT(*) as n, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l, SUM(net_profit) as pnl, AVG(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN net_profit + 2.0 END) as ap FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') AND ({cond})").fetchone()
                      dec = (r['w'] or 0) + (r['l'] or 0)
                      if dec == 0: continue
                      hr, pnl = r['w']/dec*100, r['pnl'] or 0
                      roi, ap = pnl/(dec*2.0)*100, r['ap'] or 2.0
                      emit(f"  {label:<12} {dec:>5} {hr:>6.1f}% ${ap:>6.2f} ${pnl:>+8.2f} {roi:>+6.1f}%")
              else: emit("  [is_goldmine column missing]")
              emit("```\n")
              flush()

              # â”€â”€ 2F: Exotic Payouts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2F: Exotic Payout Intelligence\n```text")
              for ex, lbl in [("superfecta_payout","SUPER"), ("trifecta_payout","TRI")]:
                  if has_col(ex):
                      erows = conn.execute(f"SELECT venue, race_number, {ex} as p, verdict FROM tips WHERE {ex} > 0 ORDER BY {ex} DESC LIMIT 5").fetchall()
                      for r in erows:
                          icon = "âœ…" if (r['verdict'] or '').startswith("CASH") else "âŒ"
                          emit(f"  {lbl:<6} {icon} ${r['p']:>8.2f} | {(r['venue'] or 'Unknown'):20s} R{r['race_number']}")
              emit("```\n")

              # â”€â”€ 2G: Odds Gap Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2G: Odds Gap vs Outcome Correlation\n```text")
              if has_col('gap12'):
                  emit(f"  {'GAP BUCKET':<20} {'BETS':>5} {'HIT%':>7} {'AVG P&L':>9}")
                  emit(f"  {'â”€'*20} {'â”€'*5} {'â”€'*7} {'â”€'*9}")
                  for label, cond in [("< 0.20 (Tight)", "CAST(gap12 AS REAL) < 0.20"), ("0.20 - 0.50", "CAST(gap12 AS REAL) >= 0.20 AND CAST(gap12 AS REAL) < 0.50"), ("0.50 - 1.00", "CAST(gap12 AS REAL) >= 0.50 AND CAST(gap12 AS REAL) < 1.00"), ("> 1.00 (Dominant)", "CAST(gap12 AS REAL) >= 1.00")]:
                      r = conn.execute(f"SELECT COUNT(*) as n, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l, AVG(net_profit) as pnl FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') AND gap12 IS NOT NULL AND {cond}").fetchone()
                      dec = (r['w'] or 0) + (r['l'] or 0)
                      if dec < 2: continue
                      emit(f"  {label:<20} {dec:>5} {r['w']/dec*100:>6.1f}% ${(r['pnl'] or 0):>+7.2f}")
              else: emit("  [gap12 column missing]")
              emit("```\n")
              flush()

              # â”€â”€ 2H: Drift Impact â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2H: Drift Impact on Performance\n```text")
              if has_col('predicted_2nd_fav_odds') and has_col('actual_2nd_fav_odds'):
                  emit(f"  {'DRIFT TYPE':<15} {'BETS':>5} {'HIT%':>7} {'ROI'}")
                  emit(f"  {'â”€'*15} {'â”€'*5} {'â”€'*7} {'â”€'*6}")
                  for label, cond in [("Tightened", "actual_2nd_fav_odds < predicted_2nd_fav_odds"), ("Stable", "actual_2nd_fav_odds = predicted_2nd_fav_odds"), ("Softened", "actual_2nd_fav_odds > predicted_2nd_fav_odds")]:
                      r = conn.execute(f"SELECT COUNT(*) as n, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l, SUM(net_profit) as pnl FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') AND ({cond})").fetchone()
                      dec = (r['w'] or 0) + (r['l'] or 0)
                      if dec == 0: continue
                      emit(f"  {label:<15} {dec:>5} {r['w']/dec*100:>6.1f}% {(r['pnl'] or 0)/(dec*2)*100:>+5.1f}%")
              else: emit("  [odds columns missing]")
              emit("```\n")

              # â”€â”€ 2I: Venue Leaderboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2I: Venue Leaderboard (Min 5 Bets)\n```text")
              emit(f"  {'VENUE':<22} {'BETS':>4} {'HIT%':>6} {'NET P&L':>8} {'ROI':>7} {'SPARK'}")
              emit(f"  {'â”€'*22} {'â”€'*4} {'â”€'*6} {'â”€'*8} {'â”€'*7} {'â”€'*5}")
              for r in conn.execute("SELECT venue, COUNT(*) as n, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l, SUM(net_profit) as pnl FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') GROUP BY venue HAVING COUNT(*) >= 5 ORDER BY pnl DESC LIMIT 10"):
                  dec = r['w'] + r['l']
                  srows = conn.execute("SELECT verdict as v FROM tips WHERE venue=? AND audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') ORDER BY start_time DESC LIMIT 5", (r['venue'],)).fetchall()
                  spark = "".join(reversed(["W" if x['v'].startswith("CASH") else "L" for x in srows]))
                  emit(f"  {(r['venue'] or 'Unknown'):22s} {dec:>4} {r['w']/dec*100:>5.0f}% ${(r['pnl'] or 0):>+7.2f} {(r['pnl'] or 0)/(dec*2)*100:>+6.1f}% {spark}")
              emit("```\n")
              flush()

              # â”€â”€ 2J: Stuck Tip Age â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2J: Stuck Tip Age Distribution\n```text")
              for r in conn.execute("SELECT CASE WHEN julianday('now')-julianday(start_time) < 1 THEN ' < 24h' WHEN julianday('now')-julianday(start_time) < 2 THEN ' 1-2d' WHEN julianday('now')-julianday(start_time) < 4 THEN ' 2-4d' ELSE ' > 4d' END as age, COUNT(*) as n FROM tips WHERE audit_completed=0 GROUP BY age ORDER BY age"):
                  emit(f"  {r['age']:<15} {r['n']:>5} tips")
              emit("```\n")

              # â”€â”€ 2K: Scoring Signal Inventory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2K: Scoring Signal Columns Inventory\n```text")
              for col in ['gap12', 'market_depth', 'place_prob', 'predicted_ev', 'qualification_grade', 'is_best_bet', 'field_size', 'composite_score', 'condition_modifier', 'source', 'match_confidence']:
                  if has_col(col):
                      filled = conn.execute(f"SELECT COUNT(*) FROM tips WHERE {col} IS NOT NULL AND {col} != '' AND {col} != 0").fetchone()[0]
                      emit(f"  {col:<22} {filled:>5} / {total} ({filled/total*100 if total else 0:>3.0f}%)")
                  else:
                      emit(f"  {col:<22}   [column missing]")
              emit("```\n")

              # â”€â”€ 2L: Qualification Grade â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2L: Performance by Qualification Grade\n```text")
              if has_col('qualification_grade'):
                  emit(f"  {'GRADE':<8} {'BETS':>5} {'HIT%':>7} {'AVG P&L':>8} {'NET P&L':>10}")
                  emit(f"  {'â”€'*8} {'â”€'*5} {'â”€'*7} {'â”€'*8} {'â”€'*10}")
                  for r in conn.execute("SELECT COALESCE(qualification_grade,'?') as g, COUNT(*) as n, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l, AVG(net_profit) as pnl, SUM(net_profit) as tpnl FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') GROUP BY g ORDER BY g"):
                      dec = r['w'] + r['l']
                      if dec == 0: continue
                      emit(f"  {(r['g'] or '?'):<8} {dec:>5} {r['w']/dec*100:>6.1f}% ${(r['pnl'] or 0):>+7.2f} ${(r['tpnl'] or 0):>+8.2f}")
              else: emit("  [grade column missing]")
              emit("```\n")
              flush()

              # â”€â”€ 2M: Match Confidence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2M: Audit Match Confidence\n```text")
              if has_col('match_confidence'):
                  emit(f"  {'CONFIDENCE':<12} {'COUNT':>8} {'% OF TOTAL':>10}")
                  emit(f"  {'â”€'*12} {'â”€'*8} {'â”€'*10}")
                  for r in conn.execute("SELECT COALESCE(match_confidence,'none') as c, COUNT(*) as n FROM tips WHERE audit_completed=1 GROUP BY c ORDER BY n DESC"):
                      pct = f"{r['n']/audited*100:>8.1f}%" if audited > 0 else "     0.0%"
                      emit(f"  {(r['c'] or 'none'):<12} {r['n']:>8} {pct}")
              else: emit("  [match_confidence missing]")
              emit("```\n")

              # â”€â”€ 2N: Superfecta Keybox Strategy Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2N: Superfecta Keybox Strategy Analysis\n```text")
              if has_col('is_superfecta_key'):
                  r = conn.execute("SELECT COUNT(*) as n, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l, SUM(net_profit) as pnl FROM tips WHERE is_superfecta_key=1 AND audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED')").fetchone()
                  dec = (r['w'] or 0) + (r['l'] or 0)
                  if dec > 0: emit(f"  Bets: {dec} | Hit%: {r['w']/dec*100:.1f}% | Net: ${(r['pnl'] or 0):+.2f}")
                  else: emit("  No Superfecta Key plays audited yet.")
              else: emit("  [is_superfecta_key missing]")
              emit("```\n")

              # â”€â”€ 2O: Tip Distribution by Time (ET) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2O: Tip Distribution by Time (ET)\n```text")
              emit(f"  {'HOUR (ET)':<12} {'COUNT':>8} {'W':>5} {'L':>5} {'HIT%':>7}")
              emit(f"  {'â”€'*12} {'â”€'*8} {'â”€'*5} {'â”€'*5} {'â”€'*7}")
              for r in conn.execute("SELECT SUBSTR(start_time, 12, 2) as hr, COUNT(*) as n, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l FROM tips GROUP BY hr ORDER BY hr"):
                  dec = r['w'] + r['l']
                  hrp = f"{r['w']/dec*100:>6.1f}%" if dec else "    â€”"
                  emit(f"  {r['hr']:02s}:00        {r['n']:>8} {r['w']:>5} {r['l']:>5} {hrp}")
              emit("```\n")
              flush()

              # â”€â”€ 2P: Discovery Adapter Coverage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2P: Discovery Adapter Yield & Accuracy\n```text")
              if has_col('source'):
                  emit(f"  {'SOURCE':<25} {'TIPS':>5} {'HIT%':>7} {'ROI'}")
                  emit(f"  {'â”€'*25} {'â”€'*5} {'â”€'*7} {'â”€'*6}")
                  for r in conn.execute("SELECT COALESCE(source,'unknown') as s, COUNT(*) as n, SUM(CASE WHEN verdict IN ('CASHED','CASHED_ESTIMATED') THEN 1 ELSE 0 END) as w, SUM(CASE WHEN verdict='BURNED' THEN 1 ELSE 0 END) as l, SUM(net_profit) as pnl FROM tips WHERE audit_completed=1 AND verdict IN ('CASHED','CASHED_ESTIMATED','BURNED') GROUP BY s ORDER BY n DESC"):
                      dec = r['w'] + r['l']
                      if dec == 0: continue
                      emit(f"  {r['s']:<25} {dec:>5} {r['w']/dec*100:>6.1f}% {(r['pnl'] or 0)/(dec*2)*100:>+5.1f}%")
              else: emit("  [source missing]")
              emit("```\n")

              # â”€â”€ 2Q: Scoring Signal Variance (Pipeline Health) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2Q: Scoring Signal Variance (Pipeline Health)\n```text")
              signals_found = False
              for sig in ['composite_score', 'place_prob', 'predicted_ev', 'market_depth']:
                  if has_col(sig):
                      r = conn.execute(f"SELECT AVG({sig}), MIN({sig}), MAX({sig}) FROM tips WHERE {sig} IS NOT NULL AND {sig} != 0").fetchone()
                      if r[0] is not None:
                          if not signals_found:
                              emit(f"  {'SIGNAL':<20} {'MEAN':>10} {'MIN':>10} {'MAX':>10}")
                              emit(f"  {'â”€'*20} {'â”€'*10} {'â”€'*10} {'â”€'*10}")
                              signals_found = True
                          emit(f"  {sig:<20} {r[0]:>10.3f} {r[1]:>10.3f} {r[2]:>10.3f}")
              if not signals_found:
                  emit("  [no scoring signals with non-zero values]")
              emit("```\n")

              # â”€â”€ 2R: Regional Tip Distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2R: Regional Tip Distribution\n```text")
              emit(f"  {'REGION':<10} {'COUNT':>8} {'% OF TOTAL':>10}")
              emit(f"  {'â”€'*10} {'â”€'*8} {'â”€'*10}")
              for r in conn.execute("SELECT CASE WHEN venue IN ('Aqueduct','Gulfstream Park','Tampa Bay Downs','Oaklawn Park','Turfway Park','Santa Anita','Golden Gate Fields','Delta Downs','Fair Grounds','Charles Town','Sam Houston','Penn National','Turf Paradise','Mahoning Valley','Parx Racing','Laurel Park','Sunland Park','Finger Lakes','Presque Isle Downs') THEN 'USA' ELSE 'INT' END as reg, COUNT(*) as n FROM tips GROUP BY reg"):
                  emit(f"  {r['reg']:<10} {r['n']:>8} {r['n']/total*100 if total else 0:>8.1f}%")
              emit("```\n")
              flush()

              # â”€â”€ 2S: Market Drift Tracking (Recent) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2S: Market Drift Tracking (Recent)\n```text")
              if has_col('predicted_2nd_fav_odds') and has_col('actual_2nd_fav_odds'):
                  emit(f"  {'VENUE':<20} {'R#':<3} {'PRED':>5} {'ACTUAL':>7} {'DRIFT':>7} {'RESULT'}")
                  emit(f"  {'â”€'*20} {'â”€'*3} {'â”€'*5} {'â”€'*7} {'â”€'*7} {'â”€'*6}")
                  for r in conn.execute("SELECT venue, race_number, predicted_2nd_fav_odds as p, actual_2nd_fav_odds as a, verdict FROM tips WHERE predicted_2nd_fav_odds IS NOT NULL AND actual_2nd_fav_odds IS NOT NULL AND audit_completed=1 ORDER BY start_time DESC LIMIT 10"):
                      drift = r['a'] - r['p']
                      icon = "âœ…" if (r['verdict'] or '').startswith("CASH") else "âŒ"
                      emit(f"  {(r['venue'] or 'Unknown'):20s} {r['race_number']:<3} {r['p']:>5.2f} {r['a']:>7.2f} {drift:>+7.2f} {icon}")
              else: emit("  [odds columns missing]")
              emit("```\n")

              # â”€â”€ 2T: Data Quality Assertions (8 Assertions) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2T: Data Quality Assertions\n```text")
              if not dq: emit("  âœ… All 8 Data Quality Assertions Passed.")
              else:
                  for d in dq: emit(f"  {d}")
              emit("```\n")

              # â”€â”€ 2U: Artifact Inventory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              emit("### 2U: Artifact Inventory\n```text")
              for art in ["summary_grid.txt", "goldmine_report.txt", "fortuna_report.html", "prediction_history.jsonl", "qualified_races.json", "analytics_report.txt"]:
                  p = Path(art)
                  if p.exists():
                      status = f"âœ… {p.stat().st_size/1024:>6.1f} KB"
                  else:
                      status = "âŒ Missing"
                  emit(f"  {art:<28} {status}")
              emit("```\n")
              flush()

          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          # PHASE 3: PIPELINE HEALTH MONITOR
          # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
          emit("## Phase 3: Pipeline Health Monitor\n")
          emit("### 3A: Harvest Success Rate (7d)\n```text")
          if has_table("harvest_logs"):
              emit(f"  {'ADAPTER':<30} {'ATTEMPTS':>8} {'OK':>5} {'RATE':>5} {'AVG R':>5}  LAST SUCCESS")
              emit(f"  {'â”€'*30} {'â”€'*8} {'â”€'*5} {'â”€'*5} {'â”€'*5}  {'â”€'*16}")
              for r in conn.execute("SELECT adapter_name as a, COUNT(*) as att, SUM(CASE WHEN race_count>0 THEN 1 ELSE 0 END) as ok, AVG(race_count) as avg, MAX(CASE WHEN race_count>0 THEN timestamp END) as last FROM harvest_logs WHERE timestamp >= DATE('now','-7 days') GROUP BY a ORDER BY ok DESC, att DESC"):
                  rate = f"{r['ok']/(r['att'] or 1)*100:3.0f}%" if r['att'] else "  0%"
                  emit(f"  {(r['a'] or 'unknown'):<30} {r['att']:>8} {r['ok']:>5} {rate:>5} {r['avg'] or 0:>5.1f}  {(r['last'] or 'never')[:16]}")
          else: emit("  [harvest_logs missing]")
          emit("```\n")

          emit("### 3B: Schema Verification\n```text")
          if has_table("schema_version"):
              r = conn.execute("SELECT version, applied_at FROM schema_version ORDER BY version DESC LIMIT 1").fetchone()
              emit(f"  Current Version: {r['version']} (Applied: {r['applied_at']})")
              required_cols = ['market_depth','place_prob','predicted_ev','qualification_grade','composite_score','is_best_bet','condition_modifier','match_confidence','source']
              missing = [c for c in required_cols if not has_col(c)]
              if missing: emit(f"  âš ï¸ MISSING COLS: {missing}")
              else: emit("  âœ… All required scoring/audit columns present.")
          else: emit("  [schema_version missing]")
          emit("```\n")

          emit("### 3C: Discovery Source Yield (7d)\n```text")
          if has_col('source'):
              emit(f"  {'SOURCE':<25} {'TIPS':>8} {'% TOTAL':>8}")
              emit(f"  {'â”€'*25} {'â”€'*8} {'â”€'*8}")
              tot_7d = conn.execute("SELECT COUNT(*) FROM tips WHERE start_time >= DATE('now','-7 days')").fetchone()[0] or 1
              for r in conn.execute("SELECT COALESCE(source,'unknown') as s, COUNT(*) as n FROM tips WHERE start_time >= DATE('now','-7 days') GROUP BY s ORDER BY n DESC"):
                  emit(f"  {r['s']:<25} {r['n']:>8} {r['n']/tot_7d*100:>8.1f}%")
          else: emit("  [source column missing]")
          emit("```\n")
          flush()

          emit("\n---\n*Audit completed at " + datetime.now(EASTERN).strftime('%Y-%m-%d %H:%M ET') + "*")
          flush()

          conn.close()
          PYEOF

      - name: Generate Legacy Summary
        if: always()
        env:
          PYTHONPATH: .    # Was missing â€” required for fortuna/fortuna_analytics imports
        run: |
          if [ -f scripts/generate_gha_summary.py ]; then
            python3 scripts/generate_gha_summary.py || true
          fi

      - name: Upload Audit Snapshots
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: audit-snapshots-${{ github.run_number }}
          path: _audit_snapshots/
          retention-days: 7
          if-no-files-found: ignore

      - name: Save Master Database
        if: always()
        uses: actions/cache/save@v4
        with:
          path: fortuna.db
          key: fortuna-db-v3-master-${{ github.run_number }}
